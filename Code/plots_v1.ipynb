{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================= Describe Stock Returns ============================================================= #\n",
    "# Input data files are available in the read-only \"../input/\" directory on Kaggle\n",
    "# ======================================================================================================================================== #\n",
    "# # Install packages on the Kaggle notebook\n",
    "# !pip install yfinance\n",
    "# !pip install pandas-datareader\n",
    "# !pip install seaborn\n",
    "# !pip install arch\n",
    "# !pip install mplfinance\n",
    "\n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as fplt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "import pandas_datareader.data as pdr # to access FRED\n",
    "from pandas_datareader.famafrench import  get_available_datasets\n",
    "\n",
    "\n",
    "# enter the FRED API key (cf. https://fred.stlouisfed.org/docs/api/api_key.html)\n",
    "fred_api_key = os.getenv(\"./Test_data/.fred_apikey\")\n",
    "\n",
    "# Define a function to download stock, bond, inflation data\n",
    "def get_stock_data(ticker: str, start_date: str, end_date: str):\n",
    "    \"\"\"\n",
    "        INPUT\n",
    "            ticker: a Yahoo! Finance stock ticker\n",
    "            start_date, end_date: start and end dates of data\n",
    "            \n",
    "            out_dir: a path to the directory where data will be stored\n",
    "        OUTPUT\n",
    "            a dataframe of all variables to be downloaded\n",
    "    \"\"\"\n",
    "    stock = yf.Ticker(ticker)\n",
    "    stock_df = stock.history(start=start_date, end=end_date)\n",
    "    stock_df.index = pd.to_datetime(stock_df.index).tz_localize(None)\n",
    "    stock_df['raw_return'] = ( (stock_df.Close + stock_df.Dividends) / ( stock_df.Close.shift(1) + stock_df.Dividends.shift(1) ) ) - 1.\n",
    "    stock_df['log_return'] = np.log(stock_df['raw_return'] + 1.)\n",
    "    stock_df['price'] = stock_df.Close\n",
    "    stock_df['Dividends_ffill'] = stock_df.Dividends.where(stock_df.Dividends > 0, np.nan).fillna(method = 'ffill', axis = 0)\n",
    "    stock_df['dp'] = stock_df.Dividends_ffill / stock_df.Close\n",
    "    stock_df.drop(columns = ['Dividends_ffill'], inplace = True)\n",
    "\n",
    "    # do the log-transform of volumes\n",
    "    stock_df['log_volume'] = np.log(stock_df['Volume'])\n",
    "\n",
    "    # get risk-free rate from Fama & French's data library\n",
    "    ff_factors_daily_df = pdr.DataReader('F-F_Research_Data_Factors_daily', 'famafrench',  start = start_date, end = end_date, api_key = fred_api_key)\n",
    "    stock_df = pd.merge(stock_df, ff_factors_daily_df[0].RF / 100, how = 'inner', left_index=True, right_index=True).drop_duplicates(keep='first').rename_axis('date').reset_index()\n",
    "    stock_df.dropna(inplace = True)\n",
    "    return stock_df\n",
    "\n",
    "##### Download data\n",
    "ticker = 'SPY'\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2023-05-10'\n",
    "\n",
    "stock_df = get_stock_data(ticker, start_date, end_date)\n",
    "display(stock_df.head() )\n",
    "\n",
    "##### Plot candlestick chart\n",
    "stock_small_df = stock_df.iloc[-100:, :].set_index('date')\n",
    "MAs = (10, 30, 50)\n",
    "kwargs = dict(type = 'candle', \n",
    "                        mav = MAs, # set sizes of moving averages\n",
    "                        volume = True,\n",
    "                        show_nontrading = True, \n",
    "                        returnfig = True,\n",
    "                        figsize = (13, 10), \n",
    "                        figscale = 1.)\n",
    "style = fplt.make_mpf_style(base_mpl_style = 'bmh', y_on_right = False, facecolor = 'w', figcolor = 'w', gridstyle = ':')\n",
    "fig, axes = fplt.plot(stock_small_df, style = style, **kwargs, title = ticker, ylabel = 'Price ($)', ylabel_lower = 'Volume')\n",
    "axes[0].legend( [None]*(len(MAs) + 2) )\n",
    "handles = axes[0].get_legend().legendHandles\n",
    "axes[0].legend(handles=handles[2:], labels= ['MA(10)', 'MA(30)', 'MA(50)'])\n",
    "fig.savefig('./Results/candlestick_chart.png', dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "##### Line plot close prices\n",
    "fig, ax = plt.subplots( figsize=(13, 10) )\n",
    "ax.plot(stock_df.date, stock_df.Close, color='cyan', linestyle='-', linewidth=2.5, label='Closing Price')\n",
    "\n",
    "# set minor ticks every quarter\n",
    "ax.xaxis.set_minor_locator( mdates.MonthLocator(interval=3) )\n",
    "\n",
    "# set major ticks format\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d') )\n",
    "plt.grid(ls=':')\n",
    "plt.xlabel('Date', fontsize=15)\n",
    "plt.ylabel(' ', fontsize=15)\n",
    "plt.xticks(rotation = 10)\n",
    "plt.legend(fontsize=10, loc='lower right')\n",
    "print(ax)\n",
    "\n",
    "##### Line plot returns\n",
    "fig, ax = plt.subplots( figsize=(13, 10) )\n",
    "ax.plot(stock_df.date, stock_df.raw_return, color='magenta', linestyle='-', linewidth=2.5, label='return')\n",
    "\n",
    "# set minor ticks every quarter\n",
    "ax.xaxis.set_minor_locator( mdates.MonthLocator(interval=3) )\n",
    "\n",
    "# set major ticks format\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d') )\n",
    "plt.grid(ls=':')\n",
    "plt.xlabel('Date', fontsize=15)\n",
    "plt.ylabel(' ', fontsize=15)\n",
    "plt.xticks(rotation = 10)\n",
    "plt.legend(fontsize=10, loc='lower right')\n",
    "print(ax)\n",
    "\n",
    "##### Histogram plot returns\n",
    "sns.displot(stock_df.raw_return, bins=20, kde=True, color=\"r\")\n",
    "plt.show()\n",
    "\n",
    "##### Plot autocorrelation of returns\n",
    "fig, ax = plt.subplots( figsize=(10, 8) )\n",
    "plt.acorr(stock_df.raw_return)\n",
    "plt.axhline(0, ls = '--', linewidth = 2, color ='red') \n",
    "plt.grid(ls=':')\n",
    "plt.xlabel('Lags', fontsize=15)\n",
    "plt.ylabel('Autocorrelation', fontsize=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================Plot Importance Scores, SHAP Values, and Performance Statistics of a Trading Strategy invested in SPY over Time ===================================== #\n",
    "# ====================================================================================================================================================== #\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from varname import nameof\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.transforms as transforms\n",
    "import seaborn as sns\n",
    "\n",
    "#Gradient Color Bar Plots\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from matplotlib import colors as mcolors, path\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import joblib\n",
    "import multiprocessing\n",
    "# import dask\n",
    "# import distributed\n",
    "# dask.config.set({\"distributed.comm.timeouts.tcp\": \"100000s\", \"distributed.scheduler.allowed-failures\": 999})\n",
    "# num_cores = multiprocessing.cpu_count()\n",
    "num_cores = 30\n",
    "\n",
    "\n",
    "##### Set the current working directory\n",
    "path=\"e:/Copy/SCRIPTS/Forecast_Stocks/Jupyter_notebooks/\"\n",
    "os.chdir(path)\n",
    "\n",
    "##### parse dates and times\n",
    "def date_parser(date): \n",
    "    dt = datetime.datetime.strptime(date, '%m/%d/%Y')\n",
    "    return dt.strftime('%Y-%m-%d') \n",
    "\n",
    "##### parse dates and times\n",
    "def date_parser2(date): \n",
    "    dt = datetime.datetime.strptime(date, '%Y:%m:%d')\n",
    "    return dt.strftime('%Y-%m-%d') \n",
    "\n",
    "##### Plot importance scores, SHAP values, and cross-validation scores generated by a ML algorithm with a given loss function and a scoring function\n",
    "def plot_test_scores(   algo = 'LGBM',\n",
    "                                    loss_fn = 'As2',\n",
    "                                    score_fn = 'Gain_to_pain_ratio_fixed_trans_cost',\n",
    "                                    n_trials = 30,\n",
    "                                    init_wealth = 1000,\n",
    "                                    fixed_trans_cost_train = 10,\n",
    "                                    variable_trans_cost_train = 0.005):\n",
    "    ''' Plot importance scores, SHAP values, and cross-validation scores generated by a ML algorithm with a given loss function and a scoring function.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    out_dir = f'../Results/{algo}/loss_fn={loss_fn}/score_fn={score_fn}/graphs'\n",
    "    if not os.path.exists( out_dir ):\n",
    "    # create the directory if it does not exist .\n",
    "        os.makedirs( out_dir )\n",
    "\n",
    "    importances_df = pd.read_csv(f'../Results/{algo}/loss_fn={loss_fn}/score_fn={score_fn}/' \\\n",
    "                                                        f'importances_1000_n_trials_{n_trials}_init_wealth_{init_wealth}_fixed_trans_cost_{fixed_trans_cost_train}_variable_trans_cost_{variable_trans_cost_train}.csv', \\\n",
    "                                                        engine = 'python', encoding = 'utf-8', skipinitialspace = True, sep = ',', parse_dates = ['start_date', 'trans_date', 'end_date'], index_col = 'end_date')\n",
    "    importances_df = importances_df.loc[:, 'dp':].astype(np.float64)\n",
    "    importances_df = importances_df.where(importances_df <= 50., 50.) # scale down the cells with their values greater than 50\n",
    "    importances_df.index = importances_df.index.to_series().dt.strftime(\"%Y-%m-%d\")\n",
    "    # display( importances_df.head() )\n",
    "    print('The shape of the importance scores dataframe is ', importances_df.shape)\n",
    "\n",
    "    shap_vals_df = pd.read_csv(f'../Results/{algo}/loss_fn={loss_fn}/score_fn={score_fn}/'\n",
    "                                                    f'SHAP_1000_n_trials_{n_trials}_init_wealth_{init_wealth}_fixed_trans_cost_{fixed_trans_cost_train}_variable_trans_cost_{variable_trans_cost_train}.csv', \\\n",
    "                                                        engine = 'python', encoding='utf-8', skipinitialspace=True, sep = ',', parse_dates=['start_date', 'trans_date', 'end_date'], index_col = 'end_date')\n",
    "    shap_vals_df = shap_vals_df.loc[:, 'dp':]\n",
    "    shap_vals_df = shap_vals_df.where(shap_vals_df <= 1., 1.) # scale down the cells with their values greater than one\n",
    "    shap_vals_df.index = shap_vals_df.index.to_series().dt.strftime(\"%Y-%m-%d\")\n",
    "    # display( shap_vals_df.head() )\n",
    "    print('The shape of the SHAP dataframe is ', shap_vals_df.shape)\n",
    "\n",
    "    cv_scores_df = pd.read_csv(f'../Results/{algo}/loss_fn={loss_fn}/score_fn={score_fn}/'\n",
    "                                                    f'scores_1000_n_trials_{n_trials}_init_wealth_{init_wealth}_fixed_trans_cost_{fixed_trans_cost_train}_variable_trans_cost_{variable_trans_cost_train}.csv', \\\n",
    "                                                            engine = 'python', encoding='utf-8', skipinitialspace=True, sep = ',', parse_dates=['start_date', 'trans_date', 'end_date'], index_col = 'end_date')\n",
    "    \n",
    "    VIX_df = pd.read_csv(f'../Data/VIX.csv', engine = 'python', encoding='utf-8', skipinitialspace=True, sep = ',', parse_dates = ['date'], index_col = 'date')\n",
    "    \n",
    "    cv_scores_VIX_df = pd.merge(cv_scores_df, VIX_df, left_index = True, right_index = True, how = 'left')\n",
    "\n",
    "    columns_to_remove = [  'start_date',\t'trans_date',\t'fit_time',\t'score_time', 'test_Average_Precision', 'test_Precision',\t'test_F1_score', 'test_Cross_entropy',\t'test_As1_score', 'test_As2_score',\t\\\n",
    "                                            'test_Boost_score',\t'test_Brier_score', 'test_Gain_to_pain_ratio_variable_trans_cost', 'test_Calmar_ratio_fixed_trans_cost', 'test_Calmar_ratio_variable_trans_cost', \\\n",
    "                                            'test_Sharpe_ratio_variable_trans_cost', 'test_Sortino_ratio_variable_trans_cost', 'test_CECPP_variable_trans_cost']\n",
    "    cv_scores_VIX_df = cv_scores_VIX_df.loc[:, ~cv_scores_VIX_df.columns.isin(columns_to_remove)] # drop some columns\n",
    "    column_mapping = {  'test_Accuracy' : 'Accuracy', \n",
    "                                        'test_AUC': 'AUC', \n",
    "                                        'test_Gain_to_pain_ratio_fixed_trans_cost': 'Gain-to-pain ratio (fixed trans. cost)',\n",
    "                                        'test_Sharpe_ratio_fixed_trans_cost': 'Sharpe ratio (fixed trans. cost)',\n",
    "                                        'test_Sortino_ratio_fixed_trans_cost': 'Sortino ratio (fixed trans. cost)',\n",
    "                                        'test_CECPP_fixed_trans_cost': 'CECPP (fixed trans. cost)'\n",
    "                                    }\n",
    "    cv_scores_VIX_df.rename(columns = column_mapping, inplace = True) # rename columns\n",
    "\n",
    "    # columns_to_std = [ 'Calmar ratio (fixed trans. cost)', 'Calmar ratio (variable trans. cost)']\n",
    "    # cv_scores_VIX_df[columns_to_std] = pd.DataFrame(StandardScaler(with_mean=False).fit_transform(cv_scores_VIX_df[columns_to_std].values), columns = columns_to_std, index = cv_scores_VIX_df.index)\n",
    "    cv_scores_VIX_df.index = cv_scores_VIX_df.index.to_series().dt.strftime(\"%Y-%m-%d\")\n",
    "    # display( cv_scores_VIX_df.head() )\n",
    "    print('The shape of the CV scores dataframe is ', cv_scores_VIX_df.shape)\n",
    "\n",
    "    ##### plot heatmap of importance scores\n",
    "    fig, ax = plt.subplots( figsize=(15, 9) )\n",
    "    ax = sns.heatmap(importances_df.T, cmap = plt.get_cmap('cool') )\n",
    "    ax.tick_params(axis='x', which='major', labelsize=9, labelrotation=70)\n",
    "    ax.set_xlabel('End Date', fontsize=15)\n",
    "    ax.set_ylabel('Features', fontsize=15)\n",
    "    # print(ax)\n",
    "    fig.savefig(f'{out_dir}/importance_scores.png', dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    ##### plot heatmap of SHAP values\n",
    "    fig, ax = plt.subplots( figsize=(15, 9) )\n",
    "    ax = sns.heatmap(shap_vals_df.T, cmap = plt.get_cmap('cool') )\n",
    "    ax.tick_params(axis='x', which='major', labelsize=9, labelrotation=70)\n",
    "    ax.set_xlabel('End Date', fontsize=15)\n",
    "    ax.set_ylabel('Features', fontsize=15)\n",
    "    # print(ax)\n",
    "    fig.savefig(f'{out_dir}/shap_vals.png', dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    ##### line plot cross-validation scores\n",
    "    axes = cv_scores_VIX_df.iloc[:, :-1].plot(kind = 'line', subplots = True, figsize = (20, 20), rot = 30, cmap = plt.get_cmap('hsv_r'), sharex = True, sharey = False)\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.axhline(0, ls = '--', linewidth = 3, color ='black') \n",
    "        ax.grid(ls=':')\n",
    "        ax1 = ax.twinx()\n",
    "        ax1.plot(cv_scores_VIX_df.index, cv_scores_VIX_df.VIX, color = \"lightsteelblue\")\n",
    "        if i == 0:\n",
    "            ax1.legend(['VIX'], loc='best', shadow = False)\n",
    "        # ax.legend(fontsize=15, bbox_to_anchor=(1.0, 1.0), shadow=True)\n",
    "        [l.set_fontsize(13) for l in ax.xaxis.get_ticklabels()]\n",
    "        [l.set_fontsize(13) for l in ax.yaxis.get_ticklabels()]\n",
    "        ax.set_xlabel('')\n",
    "    fig=axes[0].figure\n",
    "    fig.text(0.5, 0.07, \"End Date\", ha=\"center\", va=\"center\", fontsize = 15)\n",
    "    fig.text(0.1, 0.5, \"CV Scores\", ha=\"center\", va=\"center\", rotation=90, fontsize = 15)\n",
    "    fig.savefig(f'{out_dir}/cv_scores_lineplot.png', dpi=150, bbox_inches=\"tight\")\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    del cv_scores_VIX_df, cv_scores_df, VIX_df\n",
    "    gc.collect()\n",
    "\n",
    "    return True\n",
    "\n",
    "##### Plot the out-of-sample performance scores [of a trading strategy] generated by a ML algorithm with a given loss function and a scoring function\n",
    "def plot_perf_scores(  algo = 'LGBM',\n",
    "                                    loss_fn = 'As2',\n",
    "                                    score_fn = 'Gain_to_pain_ratio_fixed_trans_cost',\n",
    "                                    init_wealth = 1000,\n",
    "                                    invest_window = 200,\n",
    "                                    use_strategy = 'fixed_trans_cost',\n",
    "                                    trans_cost = 0.5):\n",
    "    ''' Plot the out-of-sample performance scores [of a trading strategy] generated by a ML algorithm with a given loss function and a scoring function.\n",
    "    INPUT\n",
    "        algo: a ML algorithm used to forecast\n",
    "        loss_fn: a loss function used to train the model\n",
    "        score_fn: a scoring function used to cross validate the model\n",
    "        init_wealth: an initial wealth used to invest\n",
    "        invest_window: an investment horizon\n",
    "        use_strategy: the trading strategy using fixed/variable transaction costs\n",
    "        trans_cost: an amount of transaction cost (i.e., fixed_trans_costs = [0.05, 0.1, 0.5, 1.0] for the fixed cost strategy \n",
    "                                                                            and  variable_trans_costs = [0.0005, 0.001, 0.005, 0.01] for the variable cost strategy)\n",
    "    OUTPUT\n",
    "        Matplotlib graphs\n",
    "    '''\n",
    "\n",
    "    out_dir = f'../Results/{algo}/loss_fn={loss_fn}/score_fn={score_fn}/graphs'\n",
    "    if not os.path.exists( out_dir ):\n",
    "    # create the directory if it does not exist .\n",
    "        os.makedirs( out_dir )\n",
    "\n",
    "    try:\n",
    "        performance_df = pd.read_csv(f'../Results/{algo}/loss_fn={loss_fn}/score_fn={score_fn}/performance/' \\\n",
    "                                                            f'performance_hper_{invest_window}_init_wealth_{init_wealth}_{use_strategy}_{trans_cost}.csv', \\\n",
    "                                                                engine = 'python', encoding='utf-8', skipinitialspace=True, sep = ',', parse_dates=['start_date', 'end_date'], index_col = 'end_date')\n",
    "    except:\n",
    "        raise Exception(f'Strategy \\'{use_strategy}\\' does not exist!')\n",
    "\n",
    "    performance_df.drop(columns = ['start_date', 'ratio_profit_over_total_loss',  'annualized_return', 'annualized_return_bh'], axis = 1, inplace = True)\n",
    "\n",
    "    VIX_df = pd.read_csv(f'../Data/VIX.csv', engine = 'python', encoding='utf-8', skipinitialspace=True, sep = ',', parse_dates = ['date'], index_col = 'date')\n",
    "    performance_df = pd.merge(performance_df, VIX_df, left_index = True, right_index = True, how = 'left')\n",
    "    \n",
    "    column_mapping = { 'average_number_of_trades': 'Average number of trades',\n",
    "                                        'percentage_of_winning_trades': 'Percentage of winning trades',\n",
    "                                        'largest_raw_return': 'Largest raw return',\t\n",
    "                                        'smallest_raw_return': 'Smallest raw return',\t\n",
    "                                        'ratio_win_loss': 'Win/loss ratio',\n",
    "                                        'max_number_of_consecutive_winners': 'Maximum number of consecutive winners',\n",
    "                                        'max_number_of_consecutive_losers': 'Maximum number of consecutive losers',\n",
    "                                        'annualized_excess_return': 'Annualized excess return',\n",
    "                                        'annualized_standard_deviation': 'Annualized standard deviation',\t\n",
    "                                        'max_drawdown': 'Maximum drawdown',\n",
    "                                        'Schwager_gain-to-pain_ratio': 'Schwager\\'s gain/pain ratio',\n",
    "                                        'Calmar_ratio': 'Calmar ratio',\n",
    "                                        'Sharpe_ratio': 'Sharpe ratio',\n",
    "                                        'Sortino_ratio': 'Sortino ratio',\n",
    "                                        'cecpp': 'CECPP',\n",
    "                                        'mrar': 'Morningstar\\'s risk-adjusted rating'\n",
    "                                    }\n",
    "    performance_df.rename(columns = column_mapping, inplace = True)\n",
    "    # display( performance_df.head() )\n",
    "    print('The shape of the performance dataframe is ', performance_df.shape)\n",
    "    \n",
    "    ##### line plot the annualized excess return of a trading strategy\n",
    "    ax = performance_df.loc[:, 'Annualized excess return'].plot(kind='line', subplots = False, figsize=(10, 7), rot=30, color = ['magenta'], sharex=True, sharey=True)\n",
    "    ax.axhline(0, ls = '--', linewidth = 3, color ='black') \n",
    "    ax.grid(ls=':')\n",
    "    ax1 = ax.twinx()\n",
    "    ax1.plot(performance_df.index, performance_df.VIX, color = \"lightsteelblue\")\n",
    "    ax1.legend(['VIX'], loc='best', shadow = False)\n",
    "    # ax.legend(fontsize=15, bbox_to_anchor=(1.0, 1.0), shadow=True)\n",
    "    [l.set_fontsize(13) for l in ax.xaxis.get_ticklabels()]\n",
    "    [l.set_fontsize(13) for l in ax.yaxis.get_ticklabels()]\n",
    "    ax.set_xlabel('End Date', fontsize = 15, fontweight = 'medium')\n",
    "    ax.set_ylabel('Annualized excess return', fontsize = 15, fontweight = 'medium')\n",
    "    fig=ax.figure\n",
    "    # fig.text(0.5, 0.15, \"End Date\", ha=\"center\", va=\"center\", fontsize = 15, fontweight = 'medium')\n",
    "    # fig.text(0.09, 0.5, \"Performance Statistics\", ha=\"center\", va=\"center\", rotation = 90, fontsize = 15, fontweight = 'medium')\n",
    "    fig.savefig(f'{out_dir}/OoS_perf_lineplot_AERet_{invest_window}_{use_strategy}_{trans_cost}.png', dpi=150, bbox_inches=\"tight\")\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # ##### line plot the statistics of a trading strategy\n",
    "    # axes = performance_df.iloc[:, :-1].plot(kind='line', subplots = True, figsize=(20, 20), rot=30, cmap = plt.get_cmap('gist_rainbow'), sharex=True, sharey=False)\n",
    "    # for i, ax in enumerate(axes):\n",
    "    #     ax.axhline(0, ls = '--', linewidth = 3, color ='black') \n",
    "    #     ax.grid(ls=':')\n",
    "    #     ax1 = ax.twinx()\n",
    "    #     ax1.plot(performance_df.index, performance_df.VIX, color = \"lightsteelblue\")\n",
    "    #     if i == 0:\n",
    "    #         ax1.legend(['VIX'], loc='best', shadow = False)\n",
    "    #     # ax.legend(fontsize=15, bbox_to_anchor=(1.0, 1.0), shadow=True)\n",
    "    #     [l.set_fontsize(13) for l in ax.xaxis.get_ticklabels()]\n",
    "    #     [l.set_fontsize(13) for l in ax.yaxis.get_ticklabels()]\n",
    "    #     ax.set_xlabel('')\n",
    "    # fig=axes[0].figure\n",
    "    # fig.text(0.5, 0.15, \"End Date\", ha=\"center\", va=\"center\", fontsize = 15, fontweight = 'medium')\n",
    "    # fig.text(0.09, 0.5, \"Performance Statistics\", ha=\"center\", va=\"center\", rotation = 90, fontsize = 15, fontweight = 'medium')\n",
    "    # fig.savefig(f'{out_dir}/OoS_perf_lineplot_{invest_window}_{use_strategy}_{trans_cost}.png', dpi=150, bbox_inches=\"tight\")\n",
    "    # # plt.show()\n",
    "    # plt.close()\n",
    "\n",
    "    # # ##### box plot the statistics of a trading strategy\n",
    "    # performance_df.drop(columns = ['Average number of trades', 'Largest raw return', 'Smallest raw return', 'Maximum number of consecutive winners', \\\n",
    "    #                                                          'Maximum number of consecutive losers', 'Maximum drawdown', 'Calmar ratio'], axis = 1, inplace = True)\n",
    "\n",
    "    # # scale up some performance metrics to put all the metrics roughly on the same scale                                               \n",
    "    # # performance_df['Annualized standard deviation'] = 10*performance_df['Annualized standard deviation']\n",
    "    # # performance_df['CECPP'] = 10*performance_df['CECPP']\n",
    "    # performance_df['Morningstar\\'s risk-adjusted rating'] = 10*performance_df['Morningstar\\'s risk-adjusted rating']\n",
    "    # performance_df['Annualized excess return'] = 10*performance_df['Annualized excess return']\n",
    "\n",
    "    # fig, ax = plt.subplots( figsize=(13, 8) )\n",
    "    # ax = sns.boxplot(data=performance_df.iloc[:, :-1])\n",
    "    # ax = sns.stripplot(data=performance_df.iloc[:, :-1], jitter=0.2, dodge=True, color='gray', size=3, alpha=0.9)\n",
    "    # ax.axhline(0, ls = '--', linewidth = 2, color ='red') \n",
    "    # ax.axhline(1, ls = '--', linewidth = 1, color ='red') \n",
    "    # # trans = transforms.blended_transform_factory(ax.get_yticklabels()[0].get_transform(), ax.transData)\n",
    "    # ax.text(-0.62, 1, \"1\", ha=\"center\", va=\"center\")\n",
    "    # ax.grid(ls=':')\n",
    "    # ax.legend(fontsize=15)\n",
    "    # ax.set_xlabel('Performance Statistics', fontsize=15)\n",
    "    # ax.set_ylabel('')\n",
    "    # ax.tick_params(axis='x', which='major', labelsize=9, labelrotation=45)\n",
    "    # fig.savefig(f'{out_dir}/OoS_perf_boxplot_{invest_window}_{use_strategy}_{trans_cost}.png', dpi=150, bbox_inches=\"tight\")\n",
    "    # # print(ax)\n",
    "    # plt.close()\n",
    "    \n",
    "    del performance_df, VIX_df\n",
    "    gc.collect()\n",
    "    \n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    startTime = time.time()\n",
    "\n",
    "    # Define a list of algorithms employed\n",
    "    # algos = ['XGB_SPY_all_vars', 'XGB_SPY_all_vars_plus_patterns']\n",
    "    algos = ['RF_SPY_all_vars', 'RF_SPY_all_vars_plus_patterns']\n",
    "    # algos = ['LGBM_SPY_all_vars', 'LGBM_SPY_all_vars_plus_patterns']\n",
    "\n",
    "    # Define a list of loss functions used to train a ML model\n",
    "    # loss_fns = ['CE', 'Brier', 'Boost', 'As1', 'As2']\n",
    "    loss_fns = ['CE']\n",
    "\n",
    "    # Define a list of score functions used to cross validate a ML algorithm\n",
    "    score_fns = ['Accuracy', 'AUC',  'Gain_to_pain_ratio_fixed_trans_cost', 'Gain_to_pain_ratio_variable_trans_cost', 'Calmar_ratio_fixed_trans_cost', \\\n",
    "                        'Calmar_ratio_variable_trans_cost', 'Sharpe_ratio_fixed_trans_cost', 'Sharpe_ratio_variable_trans_cost', 'Sortino_ratio_fixed_trans_cost', \\\n",
    "                        'Sortino_ratio_variable_trans_cost', 'CECPP_fixed_trans_cost', 'CECPP_variable_trans_cost']    \n",
    "    score_fns_fixed_trans_cost = ['Accuracy', 'AUC',  'Gain_to_pain_ratio_fixed_trans_cost', 'Calmar_ratio_fixed_trans_cost', \\\n",
    "                                                        'Sharpe_ratio_fixed_trans_cost',  'Sortino_ratio_fixed_trans_cost',  'CECPP_fixed_trans_cost']   \n",
    "    score_fns_variable_trans_cost = ['Accuracy', 'AUC',  'Gain_to_pain_ratio_variable_trans_cost', 'Calmar_ratio_variable_trans_cost', \\\n",
    "                                                            'Sharpe_ratio_variable_trans_cost', 'Sortino_ratio_variable_trans_cost', 'CECPP_variable_trans_cost']  \n",
    "\n",
    "    # Define a list of holding periods\n",
    "    invest_windows = [100, 200]\n",
    "\n",
    "    # Define transaction costs\n",
    "    fixed_trans_costs = [0.05, 0.1, 0.5, 1.0] \n",
    "    variable_trans_costs = [0.0005, 0.001, 0.005, 0.01]\n",
    "\n",
    "    try:\n",
    "        # client = Client('tcp://localhost:8786', timeout='2s')\n",
    "        cluster = LocalCluster(n_workers=num_cores, processes=True, memory_limit='auto', threads_per_worker=1, scheduler_port=8786, dashboard_address='localhost:8787')\n",
    "        client = Client(cluster)\n",
    "    except OSError:\n",
    "        client.close()\n",
    "        cluster.close()\n",
    "        time.sleep(20)\n",
    "        cluster = LocalCluster(n_workers=num_cores, processes=True, memory_limit='auto', threads_per_worker=1, scheduler_port=8786, dashboard_address='localhost:8787')\n",
    "        client = Client(cluster)\n",
    "    print(client)\n",
    "\n",
    "    # with joblib.parallel_backend('dask'):\n",
    "    #     job_run = joblib.Parallel(verbose=20) (joblib.delayed(plot_test_scores)(algo = algo, \n",
    "    #                                                                                                                         loss_fn = loss_fn, \n",
    "    #                                                                                                                         score_fn = score_fn) \\\n",
    "    #                                                                     for algo in algos\n",
    "    #                                                                         for loss_fn in loss_fns\n",
    "    #                                                                             for score_fn in score_fns)\n",
    "\n",
    "    # time.sleep(30)\n",
    "\n",
    "    with joblib.parallel_backend('dask'):\n",
    "        job_run = joblib.Parallel(verbose=20) (joblib.delayed(plot_perf_scores)(algo = algo, \n",
    "                                                                                                                            loss_fn = loss_fn, \n",
    "                                                                                                                            score_fn = score_fn, \n",
    "                                                                                                                            invest_window = invest_window, \n",
    "                                                                                                                            use_strategy = 'fixed_trans_cost', \n",
    "                                                                                                                            trans_cost = trans_cost) \\\n",
    "                                                                    for algo in algos\n",
    "                                                                        for loss_fn in loss_fns\n",
    "                                                                            for score_fn in score_fns_fixed_trans_cost\n",
    "                                                                                for invest_window in invest_windows\n",
    "                                                                                    for trans_cost in fixed_trans_costs)\n",
    "    # time.sleep(30)\n",
    "\n",
    "    # with joblib.parallel_backend('dask'):\n",
    "    #     job_run = joblib.Parallel(verbose=20) (joblib.delayed(plot_perf_scores)(algo = algo, \n",
    "    #                                                                                                                         loss_fn = loss_fn, \n",
    "    #                                                                                                                         score_fn = score_fn, \n",
    "    #                                                                                                                         invest_window = invest_window, \n",
    "    #                                                                                                                         use_strategy = 'variable_trans_cost', \n",
    "    #                                                                                                                         trans_cost = trans_cost) \\\n",
    "    #                                                                 for algo in algos\n",
    "    #                                                                     for loss_fn in loss_fns\n",
    "    #                                                                         for score_fn in score_fns_variable_trans_cost\n",
    "    #                                                                             for invest_window in invest_windows\n",
    "    #                                                                                 for trans_cost in variable_trans_costs)\n",
    "    \n",
    "    # time.sleep(30)\n",
    "\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    print( 'The script took {} second !'.format(time.time() - startTime) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://127.0.0.1:8786' processes=30 threads=30, memory=89.95 GiB>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend DaskDistributedBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:   34.5s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   34.5s\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   35.1s\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:   35.1s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   35.1s\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:   37.2s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   37.2s\n",
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:   38.5s\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:   40.7s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:   41.9s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   41.9s\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of 112 | elapsed:   45.7s remaining:   41.0s\n",
      "[Parallel(n_jobs=-1)]: Done  65 out of 112 | elapsed:   50.0s remaining:   36.1s\n",
      "[Parallel(n_jobs=-1)]: Done  71 out of 112 | elapsed:   53.4s remaining:   30.8s\n",
      "[Parallel(n_jobs=-1)]: Done  77 out of 112 | elapsed:   57.6s remaining:   26.1s\n",
      "[Parallel(n_jobs=-1)]: Done  83 out of 112 | elapsed:  1.0min remaining:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done  89 out of 112 | elapsed:  1.1min remaining:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done  95 out of 112 | elapsed:  1.1min remaining:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done 101 out of 112 | elapsed:  1.2min remaining:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 107 out of 112 | elapsed:  1.2min remaining:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 112 out of 112 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The script took 93.76251888275146 second !\n"
     ]
    }
   ],
   "source": [
    "# ===============================Plot Importance Scores, SHAP Values, and Performance Statistics of a Trading Strategy invested in BTC-USD over Time ================================= #\n",
    "# ======================================================================================================================================================= #\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.transforms as transforms\n",
    "import seaborn as sns\n",
    "\n",
    "#Gradient Color Bar Plots\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from matplotlib import colors as mcolors, path\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import joblib\n",
    "import multiprocessing\n",
    "# import dask\n",
    "# import distributed\n",
    "# dask.config.set({\"distributed.comm.timeouts.tcp\": \"100000s\", \"distributed.scheduler.allowed-failures\": 999})\n",
    "# num_cores = multiprocessing.cpu_count()\n",
    "num_cores = 30\n",
    "\n",
    "\n",
    "# ##### Set the current working directory\n",
    "# path=\"e:/Copy/SCRIPTS/Forecast_Stocks/Jupyter_notebooks/\"\n",
    "# os.chdir(path)\n",
    "\n",
    "##### parse dates and times\n",
    "def date_parser(date): \n",
    "    dt = datetime.datetime.strptime(date, '%m/%d/%Y')\n",
    "    return dt.strftime('%Y-%m-%d') \n",
    "\n",
    "##### parse dates and times\n",
    "def date_parser2(date): \n",
    "    dt = datetime.datetime.strptime(date, '%Y:%m:%d')\n",
    "    return dt.strftime('%Y-%m-%d') \n",
    "\n",
    "##### Plot importance scores, SHAP values, and cross-validation scores generated by a ML algorithm with a given loss function and a scoring function\n",
    "def plot_test_scores(   algo = 'LGBM',\n",
    "                                    loss_fn = 'As2',\n",
    "                                    tau: int = 1, # a forecast horizon\n",
    "                                    score_fn = 'Gain_to_pain_ratio_fixed_trans_cost',\n",
    "                                    n_trials = 30,\n",
    "                                    init_wealth = 1000,\n",
    "                                    fixed_trans_cost_train = 10,\n",
    "                                    variable_trans_cost_train = 0.005):\n",
    "    ''' Plot importance scores, SHAP values, and cross-validation scores generated by a ML algorithm with a given loss function and a scoring function.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    out_dir = f'../Results/{algo}/loss_fn={loss_fn}/score_fn={score_fn}/graphs'\n",
    "    if not os.path.exists( out_dir ):\n",
    "    # create the directory if it does not exist .\n",
    "        os.makedirs( out_dir )\n",
    "\n",
    "    importances_df = pd.read_csv(f'../Results/{algo}/loss_fn={loss_fn}/score_fn={score_fn}/tau={tau}/' \\\n",
    "                                                        f'importances_1000_n_trials_{n_trials}_init_wealth_{init_wealth}_fixed_trans_cost_{fixed_trans_cost_train}_variable_trans_cost_{variable_trans_cost_train}.csv', \\\n",
    "                                                        engine = 'python', encoding = 'utf-8', skipinitialspace = True, sep = ',', parse_dates = ['start_date', 'trans_date', 'end_date'], index_col = 'end_date')\n",
    "    importances_df = importances_df.loc[:, 'dp':].astype(np.float64)\n",
    "    importances_df = importances_df.where(importances_df <= 50., 50.) # scale down the cells with their values greater than 50\n",
    "    importances_df.index = importances_df.index.to_series().dt.strftime(\"%Y-%m-%d\")\n",
    "    # display( importances_df.head() )\n",
    "    print('The shape of the importance scores dataframe is ', importances_df.shape)\n",
    "\n",
    "    shap_vals_df = pd.read_csv(f'../Results/{algo}/loss_fn={loss_fn}/score_fn={score_fn}/tau={tau}/'\n",
    "                                                    f'SHAP_1000_n_trials_{n_trials}_init_wealth_{init_wealth}_fixed_trans_cost_{fixed_trans_cost_train}_variable_trans_cost_{variable_trans_cost_train}.csv', \\\n",
    "                                                        engine = 'python', encoding='utf-8', skipinitialspace=True, sep = ',', parse_dates=['start_date', 'trans_date', 'end_date'], index_col = 'end_date')\n",
    "    shap_vals_df = shap_vals_df.loc[:, 'dp':]\n",
    "    shap_vals_df = shap_vals_df.where(shap_vals_df <= 1., 1.) # scale down the cells with their values greater than one\n",
    "    shap_vals_df.index = shap_vals_df.index.to_series().dt.strftime(\"%Y-%m-%d\")\n",
    "    # display( shap_vals_df.head() )\n",
    "    print('The shape of the SHAP dataframe is ', shap_vals_df.shape)\n",
    "\n",
    "    cv_scores_df = pd.read_csv(f'../Results/{algo}/loss_fn={loss_fn}/score_fn={score_fn}/tau={tau}/'\n",
    "                                                    f'scores_1000_n_trials_{n_trials}_init_wealth_{init_wealth}_fixed_trans_cost_{fixed_trans_cost_train}_variable_trans_cost_{variable_trans_cost_train}.csv', \\\n",
    "                                                            engine = 'python', encoding='utf-8', skipinitialspace=True, sep = ',', parse_dates=['start_date', 'trans_date', 'end_date'], index_col = 'end_date')\n",
    "    \n",
    "    VIX_df = pd.read_csv(f'../Data/VIX.csv', engine = 'python', encoding='utf-8', skipinitialspace=True, sep = ',', parse_dates = ['date'], index_col = 'date')\n",
    "    \n",
    "    cv_scores_VIX_df = pd.merge(cv_scores_df, VIX_df, left_index = True, right_index = True, how = 'left')\n",
    "\n",
    "    columns_to_remove = [  'start_date',\t'trans_date',\t'fit_time',\t'score_time', 'test_Average_Precision', 'test_Precision',\t'test_F1_score', 'test_Cross_entropy',\t'test_As1_score', 'test_As2_score',\t\\\n",
    "                                            'test_Boost_score',\t'test_Brier_score', 'test_Gain_to_pain_ratio_variable_trans_cost', 'test_Calmar_ratio_fixed_trans_cost', 'test_Calmar_ratio_variable_trans_cost', \\\n",
    "                                            'test_Sharpe_ratio_variable_trans_cost', 'test_Sortino_ratio_variable_trans_cost', 'test_CECPP_variable_trans_cost']\n",
    "    cv_scores_VIX_df = cv_scores_VIX_df.loc[:, ~cv_scores_VIX_df.columns.isin(columns_to_remove)] # drop some columns\n",
    "    column_mapping = {  'test_Accuracy' : 'Accuracy', \n",
    "                                        'test_AUC': 'AUC', \n",
    "                                        'test_Gain_to_pain_ratio_fixed_trans_cost': 'Gain-to-pain ratio (fixed trans. cost)',\n",
    "                                        'test_Sharpe_ratio_fixed_trans_cost': 'Sharpe ratio (fixed trans. cost)',\n",
    "                                        'test_Sortino_ratio_fixed_trans_cost': 'Sortino ratio (fixed trans. cost)',\n",
    "                                        'test_CECPP_fixed_trans_cost': 'CECPP (fixed trans. cost)'\n",
    "                                    }\n",
    "    cv_scores_VIX_df.rename(columns = column_mapping, inplace = True) # rename columns\n",
    "\n",
    "    # columns_to_std = [ 'Calmar ratio (fixed trans. cost)', 'Calmar ratio (variable trans. cost)']\n",
    "    # cv_scores_VIX_df[columns_to_std] = pd.DataFrame(StandardScaler(with_mean=False).fit_transform(cv_scores_VIX_df[columns_to_std].values), columns = columns_to_std, index = cv_scores_VIX_df.index)\n",
    "    cv_scores_VIX_df.index = cv_scores_VIX_df.index.to_series().dt.strftime(\"%Y-%m-%d\")\n",
    "    # display( cv_scores_VIX_df.head() )\n",
    "    print('The shape of the CV scores dataframe is ', cv_scores_VIX_df.shape)\n",
    "\n",
    "    ##### plot heatmap of importance scores\n",
    "    fig, ax = plt.subplots( figsize=(15, 9) )\n",
    "    ax = sns.heatmap(importances_df.T, cmap = plt.get_cmap('cool') )\n",
    "    ax.tick_params(axis='x', which='major', labelsize=9, labelrotation=70)\n",
    "    ax.set_xlabel('End Date', fontsize=15)\n",
    "    ax.set_ylabel('Features', fontsize=15)\n",
    "    # print(ax)\n",
    "    fig.savefig(f'{out_dir}/importance_scores_tau={tau}.png', dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    ##### plot heatmap of SHAP values\n",
    "    fig, ax = plt.subplots( figsize=(15, 9) )\n",
    "    ax = sns.heatmap(shap_vals_df.T, cmap = plt.get_cmap('cool') )\n",
    "    ax.tick_params(axis='x', which='major', labelsize=9, labelrotation=70)\n",
    "    ax.set_xlabel('End Date', fontsize=15)\n",
    "    ax.set_ylabel('Features', fontsize=15)\n",
    "    # print(ax)\n",
    "    fig.savefig(f'{out_dir}/shap_vals_tau={tau}.png', dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    ##### line plot cross-validation scores\n",
    "    axes = cv_scores_VIX_df.iloc[:, :-1].plot(kind = 'line', subplots = True, figsize = (20, 20), rot = 30, cmap = plt.get_cmap('hsv_r'), sharex = True, sharey = False)\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.axhline(0, ls = '--', linewidth = 3, color ='black') \n",
    "        ax.grid(ls=':')\n",
    "        ax1 = ax.twinx()\n",
    "        ax1.plot(cv_scores_VIX_df.index, cv_scores_VIX_df.VIX, color = \"lightsteelblue\")\n",
    "        if i == 0:\n",
    "            ax1.legend(['VIX'], loc='best', shadow = False)\n",
    "        # ax.legend(fontsize=15, bbox_to_anchor=(1.0, 1.0), shadow=True)\n",
    "        [l.set_fontsize(13) for l in ax.xaxis.get_ticklabels()]\n",
    "        [l.set_fontsize(13) for l in ax.yaxis.get_ticklabels()]\n",
    "        ax.set_xlabel('')\n",
    "    fig=axes[0].figure\n",
    "    fig.text(0.5, 0.07, \"End Date\", ha=\"center\", va=\"center\", fontsize = 15)\n",
    "    fig.text(0.1, 0.5, \"CV Scores\", ha=\"center\", va=\"center\", rotation=90, fontsize = 15)\n",
    "    fig.savefig(f'{out_dir}/cv_scores_lineplot_tau={tau}.png', dpi=150, bbox_inches=\"tight\")\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    del cv_scores_VIX_df, cv_scores_df, VIX_df\n",
    "    gc.collect()\n",
    "\n",
    "    return True\n",
    "\n",
    "##### Plot the out-of-sample performance scores [of a trading strategy] generated by a ML algorithm with a given loss function and a scoring function\n",
    "def plot_perf_scores(  algo = 'LGBM',\n",
    "                                    loss_fn = 'As2',\n",
    "                                    tau: int = 1, # a forecast horizon\n",
    "                                    score_fn = 'Gain_to_pain_ratio_fixed_trans_cost',\n",
    "                                    init_wealth = 1000,\n",
    "                                    invest_window = 200,\n",
    "                                    use_strategy = 'fixed_trans_cost',\n",
    "                                    trans_cost = 0.5):\n",
    "    ''' Plot the out-of-sample performance scores [of a trading strategy] generated by a ML algorithm with a given loss function and a scoring function.\n",
    "    INPUT\n",
    "        algo: a ML algorithm used to forecast\n",
    "        loss_fn: a loss function used to train the model\n",
    "        score_fn: a scoring function used to cross validate the model\n",
    "        init_wealth: an initial wealth used to invest\n",
    "        invest_window: an investment horizon\n",
    "        use_strategy: the trading strategy using fixed/variable transaction costs\n",
    "        trans_cost: an amount of transaction cost (i.e., fixed_trans_costs = [0.05, 0.1, 0.5, 1.0] for the fixed cost strategy \n",
    "                                                                            and  variable_trans_costs = [0.0005, 0.001, 0.005, 0.01] for the variable cost strategy)\n",
    "    OUTPUT\n",
    "        Matplotlib graphs\n",
    "    '''\n",
    "\n",
    "    out_dir = f'../Results/{algo}/loss_fn={loss_fn}/score_fn={score_fn}/graphs'\n",
    "    if not os.path.exists( out_dir ):\n",
    "    # create the directory if it does not exist .\n",
    "        os.makedirs( out_dir )\n",
    "\n",
    "    try:\n",
    "        performance_df = pd.read_csv(f'../Results/{algo}/loss_fn={loss_fn}/score_fn={score_fn}/tau={tau}/performance/' \\\n",
    "                                                            f'performance_hper_{invest_window}_init_wealth_{init_wealth}_{use_strategy}_{trans_cost}.csv', \\\n",
    "                                                                engine = 'python', encoding='utf-8', skipinitialspace=True, sep = ',', parse_dates=['start_date', 'end_date'], index_col = 'end_date')\n",
    "    except:\n",
    "        raise Exception(f'Strategy \\'{use_strategy}\\' does not exist!')\n",
    "\n",
    "    performance_df.drop(columns = ['start_date', 'ratio_profit_over_total_loss',  'annualized_return', 'annualized_return_bh'], axis = 1, inplace = True)\n",
    "\n",
    "    BTC_df = pd.read_csv(f'../Data/BTC-USD/BTC-USD.csv', engine = 'python', encoding='utf-8', skipinitialspace=True, sep = ',', parse_dates = ['date'], index_col = 'date')\n",
    "    performance_df = pd.merge(performance_df, BTC_df['price'], left_index = True, right_index = True, how = 'left')\n",
    "    \n",
    "    column_mapping = { 'average_number_of_trades': 'Average number of trades',\n",
    "                                        'percentage_of_winning_trades': 'Percentage of winning trades',\n",
    "                                        'largest_raw_return': 'Largest raw return',\t\n",
    "                                        'smallest_raw_return': 'Smallest raw return',\t\n",
    "                                        'ratio_win_loss': 'Win/loss ratio',\n",
    "                                        'max_number_of_consecutive_winners': 'Maximum number of consecutive winners',\n",
    "                                        'max_number_of_consecutive_losers': 'Maximum number of consecutive losers',\n",
    "                                        'annualized_excess_return': 'Annualized excess return',\n",
    "                                        'annualized_standard_deviation': 'Annualized standard deviation',\t\n",
    "                                        'max_drawdown': 'Maximum drawdown',\n",
    "                                        'Schwager_gain-to-pain_ratio': 'Schwager\\'s gain/pain ratio',\n",
    "                                        'Calmar_ratio': 'Calmar ratio',\n",
    "                                        'Sharpe_ratio': 'Sharpe ratio',\n",
    "                                        'Sortino_ratio': 'Sortino ratio',\n",
    "                                        'cecpp': 'CECPP',\n",
    "                                        'mrar': 'Morningstar\\'s risk-adjusted rating',\n",
    "\t\t\t\t\t\t\t\t\t\t'price': 'BTC-USD'\n",
    "                                    }\n",
    "    performance_df.rename(columns = column_mapping, inplace = True)\n",
    "    # display( performance_df.head() )\n",
    "    print('The shape of the performance dataframe is ', performance_df.shape)\n",
    "    \n",
    "    ##### line plot the annualized excess return of a trading strategy\n",
    "    ax = performance_df.loc[:, 'Annualized excess return'].plot(kind='line', subplots = False, figsize=(10, 7), rot=30, color = ['magenta'], sharex=True, sharey=True)\n",
    "    ax.axhline(0, ls = '--', linewidth = 3, color ='black') \n",
    "    ax.grid(ls=':')\n",
    "    ax1 = ax.twinx()\n",
    "    ax1.plot(performance_df.index, performance_df['BTC-USD'], color = \"lightsteelblue\")\n",
    "    ax1.legend(['BTC-USD'], loc='best', shadow = False)\n",
    "    # ax.legend(fontsize=15, bbox_to_anchor=(1.0, 1.0), shadow=True)\n",
    "    [l.set_fontsize(13) for l in ax.xaxis.get_ticklabels()]\n",
    "    [l.set_fontsize(13) for l in ax.yaxis.get_ticklabels()]\n",
    "    ax.set_xlabel('End Date', fontsize = 15, fontweight = 'medium')\n",
    "    ax.set_ylabel('Annualized excess return', fontsize = 15, fontweight = 'medium')\n",
    "    fig=ax.figure\n",
    "    # fig.text(0.5, 0.15, \"End Date\", ha=\"center\", va=\"center\", fontsize = 15, fontweight = 'medium')\n",
    "    # fig.text(0.09, 0.5, \"Performance Statistics\", ha=\"center\", va=\"center\", rotation = 90, fontsize = 15, fontweight = 'medium')\n",
    "    fig.savefig(f'{out_dir}/OoS_perf_lineplot_AERet_{invest_window}_{use_strategy}_{trans_cost}_tau={tau}.png', dpi=150, bbox_inches=\"tight\")\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    ##### line plot the statistics of a trading strategy\n",
    "    axes = performance_df.iloc[:, :-1].plot(kind='line', subplots = True, figsize=(20, 20), rot=30, cmap = plt.get_cmap('gist_rainbow'), sharex=True, sharey=False)\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.axhline(0, ls = '--', linewidth = 3, color ='black') \n",
    "        ax.grid(ls=':')\n",
    "        ax1 = ax.twinx()\n",
    "        ax1.plot(performance_df.index, performance_df['BTC-USD'], color = \"lightsteelblue\")\n",
    "        if i == 0:\n",
    "            ax1.legend(['BTC-USD'], loc='best', shadow = False)\n",
    "        # ax.legend(fontsize=15, bbox_to_anchor=(1.0, 1.0), shadow=True)\n",
    "        [l.set_fontsize(13) for l in ax.xaxis.get_ticklabels()]\n",
    "        [l.set_fontsize(13) for l in ax.yaxis.get_ticklabels()]\n",
    "        ax.set_xlabel('')\n",
    "    fig=axes[0].figure\n",
    "    fig.text(0.5, 0.15, \"End Date\", ha=\"center\", va=\"center\", fontsize = 15, fontweight = 'medium')\n",
    "    fig.text(0.09, 0.5, \"Performance Statistics\", ha=\"center\", va=\"center\", rotation = 90, fontsize = 15, fontweight = 'medium')\n",
    "    fig.savefig(f'{out_dir}/OoS_perf_lineplot_{invest_window}_{use_strategy}_{trans_cost}.png', dpi=150, bbox_inches=\"tight\")\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # # ##### box plot the statistics of a trading strategy\n",
    "    # performance_df.drop(columns = ['Average number of trades', 'Largest raw return', 'Smallest raw return', 'Maximum number of consecutive winners', \\\n",
    "    #                                                          'Maximum number of consecutive losers', 'Maximum drawdown', 'Calmar ratio'], axis = 1, inplace = True)\n",
    "\n",
    "    # # scale up some performance metrics to put all the metrics roughly on the same scale                                               \n",
    "    # # performance_df['Annualized standard deviation'] = 10*performance_df['Annualized standard deviation']\n",
    "    # # performance_df['CECPP'] = 10*performance_df['CECPP']\n",
    "    # performance_df['Morningstar\\'s risk-adjusted rating'] = 10*performance_df['Morningstar\\'s risk-adjusted rating']\n",
    "    # performance_df['Annualized excess return'] = 10*performance_df['Annualized excess return']\n",
    "\n",
    "    # fig, ax = plt.subplots( figsize=(13, 8) )\n",
    "    # ax = sns.boxplot(data=performance_df.iloc[:, :-1])\n",
    "    # ax = sns.stripplot(data=performance_df.iloc[:, :-1], jitter=0.2, dodge=True, color='gray', size=3, alpha=0.9)\n",
    "    # ax.axhline(0, ls = '--', linewidth = 2, color ='red') \n",
    "    # ax.axhline(1, ls = '--', linewidth = 1, color ='red') \n",
    "    # # trans = transforms.blended_transform_factory(ax.get_yticklabels()[0].get_transform(), ax.transData)\n",
    "    # ax.text(-0.62, 1, \"1\", ha=\"center\", va=\"center\")\n",
    "    # ax.grid(ls=':')\n",
    "    # ax.legend(fontsize=15)\n",
    "    # ax.set_xlabel('Performance Statistics', fontsize=15)\n",
    "    # ax.set_ylabel('')\n",
    "    # ax.tick_params(axis='x', which='major', labelsize=9, labelrotation=45)\n",
    "    # fig.savefig(f'{out_dir}/OoS_perf_boxplot_{invest_window}_{use_strategy}_{trans_cost}.png', dpi=150, bbox_inches=\"tight\")\n",
    "    # # print(ax)\n",
    "    # plt.close()\n",
    "    \n",
    "    del performance_df, BTC_df\n",
    "    gc.collect()\n",
    "    \n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    startTime = time.time()\n",
    "\n",
    "    # Define a list of algorithms employed\n",
    "    # algos = ['XGB_SPY_all_vars', 'XGB_SPY_all_vars_plus_patterns']\n",
    "    algos = ['RF_BTC_all_vars', 'RF_BTC_all_vars_plus_patterns']\n",
    "    # algos = ['LGBM_SPY_all_vars', 'LGBM_SPY_all_vars_plus_patterns']\n",
    "\n",
    "    # Define a list of loss functions used to train a ML model\n",
    "    # loss_fns = ['CE', 'Brier', 'Boost', 'As1', 'As2']\n",
    "    loss_fns = ['CE']\n",
    "    \n",
    "    # Define the forecast horizon\n",
    "    tau = 1\n",
    "\n",
    "    # Define a list of score functions used to cross validate a ML algorithm\n",
    "    score_fns = ['Accuracy', 'AUC',  'Gain_to_pain_ratio_fixed_trans_cost', 'Gain_to_pain_ratio_variable_trans_cost', 'Calmar_ratio_fixed_trans_cost', \\\n",
    "                        'Calmar_ratio_variable_trans_cost', 'Sharpe_ratio_fixed_trans_cost', 'Sharpe_ratio_variable_trans_cost', 'Sortino_ratio_fixed_trans_cost', \\\n",
    "                        'Sortino_ratio_variable_trans_cost', 'CECPP_fixed_trans_cost', 'CECPP_variable_trans_cost']    \n",
    "    score_fns_fixed_trans_cost = ['Accuracy', 'AUC',  'Gain_to_pain_ratio_fixed_trans_cost', 'Calmar_ratio_fixed_trans_cost', \\\n",
    "                                                        'Sharpe_ratio_fixed_trans_cost',  'Sortino_ratio_fixed_trans_cost',  'CECPP_fixed_trans_cost']   \n",
    "    score_fns_variable_trans_cost = ['Accuracy', 'AUC',  'Gain_to_pain_ratio_variable_trans_cost', 'Calmar_ratio_variable_trans_cost', \\\n",
    "                                                            'Sharpe_ratio_variable_trans_cost', 'Sortino_ratio_variable_trans_cost', 'CECPP_variable_trans_cost']  \n",
    "\n",
    "    # Define a list of holding periods\n",
    "    invest_windows = [100, 200]\n",
    "\n",
    "    # Define transaction costs\n",
    "    fixed_trans_costs = [0.05, 0.1, 0.5, 1.0] \n",
    "    variable_trans_costs = [0.0005, 0.001, 0.005, 0.01]\n",
    "\n",
    "    try:\n",
    "        # client = Client('tcp://localhost:8786', timeout='2s')\n",
    "        cluster = LocalCluster(n_workers=num_cores, processes=True, memory_limit='auto', threads_per_worker=1, scheduler_port=8786, dashboard_address='localhost:8787')\n",
    "        client = Client(cluster)\n",
    "    except OSError:\n",
    "        client.close()\n",
    "        cluster.close()\n",
    "        time.sleep(20)\n",
    "        cluster = LocalCluster(n_workers=num_cores, processes=True, memory_limit='auto', threads_per_worker=1, scheduler_port=8786, dashboard_address='localhost:8787')\n",
    "        client = Client(cluster)\n",
    "    print(client)\n",
    "\n",
    "    # with joblib.parallel_backend('dask'):\n",
    "    #     job_run = joblib.Parallel(verbose=20) (joblib.delayed(plot_test_scores)(algo = algo, \n",
    "    #                                                                                                                         tau = tau,\n",
    "    #                                                                                                                         loss_fn = loss_fn, \n",
    "    #                                                                                                                         score_fn = score_fn) \\\n",
    "    #                                                                     for algo in algos\n",
    "    #                                                                         for loss_fn in loss_fns\n",
    "    #                                                                             for score_fn in score_fns)\n",
    "\n",
    "    # time.sleep(30)\n",
    "\n",
    "    with joblib.parallel_backend('dask'):\n",
    "        job_run = joblib.Parallel(verbose=20) (joblib.delayed(plot_perf_scores)(algo = algo, \n",
    "                                                                                                                            tau = tau,\n",
    "                                                                                                                            loss_fn = loss_fn, \n",
    "                                                                                                                            score_fn = score_fn, \n",
    "                                                                                                                            invest_window = invest_window, \n",
    "                                                                                                                            use_strategy = 'fixed_trans_cost', \n",
    "                                                                                                                            trans_cost = trans_cost) \\\n",
    "                                                                    for algo in algos\n",
    "                                                                        for loss_fn in loss_fns\n",
    "                                                                            for score_fn in score_fns_fixed_trans_cost\n",
    "                                                                                for invest_window in invest_windows\n",
    "                                                                                    for trans_cost in fixed_trans_costs)\n",
    "    # time.sleep(30)\n",
    "\n",
    "    # with joblib.parallel_backend('dask'):\n",
    "    #     job_run = joblib.Parallel(verbose=20) (joblib.delayed(plot_perf_scores)(algo = algo, \n",
    "    #                                                                                                                         loss_fn = loss_fn, \n",
    "    #                                                                                                                         score_fn = score_fn, \n",
    "    #                                                                                                                         invest_window = invest_window, \n",
    "    #                                                                                                                         use_strategy = 'variable_trans_cost', \n",
    "    #                                                                                                                         trans_cost = trans_cost) \\\n",
    "    #                                                                 for algo in algos\n",
    "    #                                                                     for loss_fn in loss_fns\n",
    "    #                                                                         for score_fn in score_fns_variable_trans_cost\n",
    "    #                                                                             for invest_window in invest_windows\n",
    "    #                                                                                 for trans_cost in variable_trans_costs)\n",
    "    \n",
    "    # time.sleep(30)\n",
    "\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    print( 'The script took {} second !'.format(time.time() - startTime) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================= Compare the Performance of a Trading Strategy Across Various Score Functions ==================================== #\n",
    "# =========================================================================================================================================== #\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from varname import nameof\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "#Gradient Color Bar Plots\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from matplotlib import colors as mcolors, path\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import joblib\n",
    "import multiprocessing\n",
    "# import dask\n",
    "# import distributed\n",
    "# dask.config.set({\"distributed.comm.timeouts.tcp\": \"100000s\", \"distributed.scheduler.allowed-failures\": 999})\n",
    "# num_cores = multiprocessing.cpu_count()\n",
    "num_cores = 30\n",
    "\n",
    "##### Set the current working directory\n",
    "path=\"e:/Copy/SCRIPTS/Forecast_Stocks/Jupyter_notebooks/\"\n",
    "os.chdir(path)\n",
    "\n",
    "##### Joint-boxplot a performance statistic of a trading strategy over different values of the fixed/variable transaction cost with hue = score function\n",
    "def joint_plot( algo = 'LGBM_SPY_all_vars',\n",
    "                        loss_fn = 'CE',\n",
    "                        score_fns_dict = {  'Accuracy': 'Accuracy', 'AUC': 'AUC',  'Schwager\\'s gain/pain ratio': 'Gain_to_pain_ratio_variable_trans_cost', \\\n",
    "                                                        'Calmar ratio': 'Calmar_ratio_variable_trans_cost', 'Sharpe ratio': 'Sharpe_ratio_variable_trans_cost', \\\n",
    "                                                        'Sortino ratio': 'Sortino_ratio_variable_trans_cost',  'CECPP': 'CECPP_variable_trans_cost'},\n",
    "                        init_wealth = 1000,\n",
    "                        invest_window = 100,\n",
    "                        trans_costs = [0.0005, 0.005],\n",
    "                        perf_stats_dict = {  'Average Number of Trades': 'average_number_of_trades',\n",
    "                                                        'Percentage of Winning Trades': 'percentage_of_winning_trades',\t\n",
    "                                                        'Largest Simple Return':   'largest_raw_return',\t\n",
    "                                                        'Smallest Simple Return':    'smallest_raw_return',\t\n",
    "                                                        'Ratio of Average Winning Trade to Average Losing Trade': 'ratio_win_loss',\t\n",
    "                                                        'Maximum Number of Consecutive Winners': 'max_number_of_consecutive_winners',\t\n",
    "                                                        'Maximum Number of Consecutive Losers':    'max_number_of_consecutive_losers', \n",
    "                                                        'Annualized Excess Return':    'annualized_excess_return',\t\n",
    "                                                        'Annualized Standard Deviation':    'annualized_standard_deviation',\t\n",
    "                                                        'Maximum Drawdown':   'max_drawdown',\t\n",
    "                                                        'Schwager\\'s Gain to Pain Ratio': 'Schwager_gain-to-pain_ratio',\t\n",
    "                                                        'Calmar Ratio':  'Calmar_ratio',\t\n",
    "                                                        'Sharpe Ratio':    'Sharpe_ratio',\t\n",
    "                                                        'Sortino Ratio': 'Sortino_ratio',\n",
    "                                                        'CECPP': 'cecpp',\n",
    "                                                        'Morningstar\\'s risk-adjusted rating': 'mrar'}):\n",
    "\n",
    "    ''' Joint plot performance statistics of a trading strategy over different values of the fixed/variable transaction cost with hue = score function\n",
    "    INPUT\n",
    "        algo: a ML algorithm used to forecast price movement directions\n",
    "        loss_fn: a loss function used to train a ML model\n",
    "        score_fns_dict: a dictionary of score functions used to cross-validate a ML model\n",
    "            (i.e., score_fns_dict = {  'Accuracy': 'Accuracy', 'AUC': 'AUC',  'Schwager\\'s gain/pain ratio': 'Gain_to_pain_ratio_fixed_trans_cost', \\\n",
    "                                                    'Calmar ratio': 'Calmar_ratio_fixed_trans_cost', 'Sharpe ratio': 'Sharpe_ratio_fixed_trans_cost', \\\n",
    "                                                    'Sortino ratio': 'Sortino_ratio_fixed_trans_cost',  'CECPP': 'CECPP_fixed_trans_cost'} for the fixed cost strategy\n",
    "            and score_fns_dict = {  'Accuracy': 'Accuracy', 'AUC': 'AUC',  'Schwager\\'s gain/pain ratio': 'Gain_to_pain_ratio_variable_trans_cost', \\\n",
    "                                                    'Calmar ratio': 'Calmar_ratio_variable_trans_cost', 'Sharpe ratio': 'Sharpe_ratio_variable_trans_cost', \\\n",
    "                                                    'Sortino ratio': 'Sortino_ratio_variable_trans_cost',  'CECPP': 'CECPP_variable_trans_cost'} for the variable cost strategy)\n",
    "        init_wealth: an initial wealth\n",
    "        invest_window: a trading window\n",
    "        trans_costs: a list of transaction costs (i.e., trans_costs = [0.05, 0.1, 0.5, 1.0] for the fixed cost strategy \n",
    "                                                                        and  trans_costs = [0.0005, 0.001, 0.005, 0.01] for the variable cost strategy)\n",
    "        perf_stats_dict: a dictionary of performance statistics\n",
    "    OUTPUT\n",
    "        joint boxplots of performance statistics against transaction costs for various score functions\n",
    "    '''\n",
    "\n",
    "    out_dir = f'../Results/{algo}/loss_fn={loss_fn}/graphs'\n",
    "    if not os.path.exists( out_dir ):\n",
    "    # create the directory if it does not exist .\n",
    "        os.makedirs( out_dir )\n",
    "\n",
    "    # import data into dataframes\n",
    "    list_dfs = [[] for _ in np.arange( len(score_fns_dict) )]\n",
    "    try:\n",
    "        score_fns_dict_keys = list( score_fns_dict.keys() )\n",
    "        score_fns_dict_values = list( score_fns_dict.values() )\n",
    "        use_strategy = re.search(r'(?<=ratio\\_)\\w+', score_fns_dict_values[2], flags=re.IGNORECASE | re.VERBOSE).group()\n",
    "        for i in np.arange( len(score_fns_dict) ):\n",
    "            for j in np.arange( len(trans_costs) ):\n",
    "                performance_df = pd.read_csv(f'../Results/{algo}/loss_fn={loss_fn}/score_fn={score_fns_dict_values[i]}/performance/' \\\n",
    "                                                                    f'performance_hper_{invest_window}_init_wealth_{init_wealth}_{use_strategy}_{trans_costs[j]}.csv', \\\n",
    "                                                                        engine = 'python', encoding='utf-8', skipinitialspace=True, sep = ',', parse_dates=['start_date', 'end_date'], index_col = 'end_date')\n",
    "                performance_df.drop(columns = ['start_date', 'ratio_profit_over_total_loss',  'annualized_return', 'annualized_return_bh'], axis = 1, inplace = True)\n",
    "                # # scale down the values of the Calmar ratio so that all the variables are roughly on the same scale\n",
    "                # performance_df['Calmar_ratio'] = StandardScaler(with_mean=False).fit_transform( performance_df['Calmar_ratio'].values.reshape(-1,1) )\n",
    "                # display(performance_df.head() )\n",
    "                list_dfs[i].append(performance_df)\n",
    "    except Exception as er:\n",
    "        print(er)\n",
    "\n",
    "    # melt all the dataframes to a long dataframe\n",
    "    list_metric_dfs = []\n",
    "    perf_stats_values = list( perf_stats_dict.values() )\n",
    "    for i in np.arange( len(score_fns_dict) ):\n",
    "        for j in np.arange( len(trans_costs) ):\n",
    "            metric_df = list_dfs[i][j][perf_stats_values].reset_index(drop = False)\n",
    "            metric_melted_df = pd.melt(metric_df, id_vars = 'end_date', var_name='perf_stats', value_name='value')\n",
    "            metric_melted_df['score_fn'] = [score_fns_dict_keys[i] for _ in range( len(metric_melted_df ) )]\n",
    "            metric_melted_df['trans_cost'] = [trans_costs[j] for _ in range( len(metric_melted_df ) )]\n",
    "            list_metric_dfs.append(metric_melted_df)\n",
    "    merged_df = pd.concat(list_metric_dfs, axis = 0)\n",
    "    # display( merged_df.head() )\n",
    "    # merged_df.to_csv(os.path.join(out_dir, 'merged_data.csv'), index=False, header = True) \n",
    "\n",
    "    # joint boxplot each performance statistic\n",
    "    perf_stats_keys = list( perf_stats_dict.keys() )\n",
    "    for i in np.arange( len(perf_stats_dict) ):\n",
    "        fig, ax = plt.subplots( figsize=(13, 8) )\n",
    "        perf_stat_df = merged_df[ merged_df['perf_stats'] == perf_stats_values[i] ]\n",
    "        # display( perf_stat_df.head() )\n",
    "        ax = sns.boxplot(x = 'trans_cost', y = 'value', hue='score_fn', data=perf_stat_df)\n",
    "        sns.stripplot(x = 'trans_cost', y = 'value', hue='score_fn', data=perf_stat_df, jitter=0.12, dodge=True, color='gray', size=2, alpha=0.8, ax = ax)\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.axhline(0, ls = '--', linewidth = 2, color ='red') \n",
    "        # ax.axhline(1, ls = '--', linewidth = 1, color ='red') \n",
    "        # ax.text(0, 1, \"1\", ha=\"center\", va=\"center\")\n",
    "        ax.grid(ls=':')\n",
    "        ax.legend(handles, labels[0:7], fontsize=10, loc = 'upper right', title = 'Scoring functions')\n",
    "        ax.set_ylabel(perf_stats_keys[i], fontsize=15)\n",
    "        ax.set_xlabel('Transaction Cost', fontsize=15)\n",
    "        ax.tick_params(axis='x', which='major', labelsize=13, labelrotation=0)        \n",
    "        out_file = f'{out_dir}/joint_boxplot_{invest_window}_init_wealth_{init_wealth}_{use_strategy}_{perf_stats_values[i]}.png'\n",
    "        fig.savefig(out_file, dpi=150, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "    del perf_stat_df, merged_df, metric_df, performance_df\n",
    "    gc.collect()\n",
    "\n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    startTime = time.time()\n",
    "\n",
    "    # Define a list of algorithms employed\n",
    "    algos = ['RF_SPY_all_vars', 'RF_SPY_all_vars_plus_patterns', 'XGB_SPY_all_vars', 'XGB_SPY_all_vars_plus_patterns']\n",
    "    # algos = ['LGBM_SPY_all_vars', 'LGBM_SPY_all_vars_plus_patterns']\n",
    "\n",
    "    # Define a list of loss functions used to train a ML model\n",
    "    # loss_fns = ['CE', 'Brier', 'Boost', 'As1', 'As2']\n",
    "    loss_fns = ['CE']\n",
    "\n",
    "    # Define a list of score functions used to cross validate a ML algorithm\n",
    "    score_fns_fixed_trans_cost_dict = {'Accuracy': 'Accuracy', 'AUC': 'AUC',  'Schwager\\'s gain/pain ratio': 'Gain_to_pain_ratio_fixed_trans_cost', \\\n",
    "                                                                'Calmar ratio': 'Calmar_ratio_fixed_trans_cost', 'Sharpe ratio': 'Sharpe_ratio_fixed_trans_cost', \\\n",
    "                                                                'Sortino ratio': 'Sortino_ratio_fixed_trans_cost',  'CECPP': 'CECPP_fixed_trans_cost'}\n",
    "    score_fns_variable_trans_cost_dict = {'Accuracy': 'Accuracy', 'AUC': 'AUC',  'Schwager\\'s gain/pain ratio': 'Gain_to_pain_ratio_variable_trans_cost', \\\n",
    "                                                                    'Calmar ratio': 'Calmar_ratio_variable_trans_cost', 'Sharpe ratio': 'Sharpe_ratio_variable_trans_cost', \\\n",
    "                                                                    'Sortino ratio': 'Sortino_ratio_variable_trans_cost',  'CECPP': 'CECPP_variable_trans_cost'} \n",
    "    # Define a list of holding periods\n",
    "    invest_windows = [100, 200]\n",
    "\n",
    "    try:\n",
    "        # client = Client('tcp://localhost:8786', timeout='2s')\n",
    "        cluster = LocalCluster(n_workers=num_cores, processes=True, memory_limit='auto', threads_per_worker=1, scheduler_port=8786, dashboard_address='localhost:8787')\n",
    "        client = Client(cluster)\n",
    "    except OSError:\n",
    "        client.close()\n",
    "        cluster.close()\n",
    "        time.sleep(20)\n",
    "        cluster = LocalCluster(n_workers=num_cores, processes=True, memory_limit='auto', threads_per_worker=1, scheduler_port=8786, dashboard_address='localhost:8787')\n",
    "        client = Client(cluster)\n",
    "    print(client)\n",
    "\n",
    "    with joblib.parallel_backend('dask'):\n",
    "        job_run = joblib.Parallel(verbose=20) (joblib.delayed(joint_plot)(  algo = algo,\n",
    "                                                                                                                    loss_fn = loss_fn,\n",
    "                                                                                                                    score_fns_dict = score_fns_fixed_trans_cost_dict,\n",
    "                                                                                                                    invest_window = invest_window,\n",
    "                                                                                                                    trans_costs = [0.05, 0.5]) \\\n",
    "                                                                        for algo in algos\n",
    "                                                                            for loss_fn in loss_fns\n",
    "                                                                                for invest_window in invest_windows)\n",
    "    time.sleep(30)\n",
    "\n",
    "    with joblib.parallel_backend('dask'):\n",
    "        job_run = joblib.Parallel(verbose=20) (joblib.delayed(joint_plot)(  algo = algo,\n",
    "                                                                                                                    loss_fn = loss_fn,\n",
    "                                                                                                                    score_fns_dict = score_fns_variable_trans_cost_dict,\n",
    "                                                                                                                    invest_window = invest_window,\n",
    "                                                                                                                    trans_costs = [0.0005, 0.005]) \\\n",
    "                                                                        for algo in algos\n",
    "                                                                            for loss_fn in loss_fns\n",
    "                                                                                for invest_window in invest_windows)\n",
    "\n",
    "    time.sleep(30)\n",
    "\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "    \n",
    "    print( 'The script took {} second !'.format(time.time() - startTime) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================= Compare the Performance of a Trading Strategy Across Various Loss Functions ==================================== #\n",
    "# =========================================================================================================================================== #\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "#Gradient Color Bar Plots\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from matplotlib import colors as mcolors, path\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import joblib\n",
    "import multiprocessing\n",
    "# import dask\n",
    "# import distributed\n",
    "# dask.config.set({\"distributed.comm.timeouts.tcp\": \"100000s\", \"distributed.scheduler.allowed-failures\": 999})\n",
    "# num_cores = multiprocessing.cpu_count()\n",
    "num_cores = 30\n",
    "\n",
    "##### Set the current working directory\n",
    "path=\"e:/Copy/SCRIPTS/Forecast_Stocks/Jupyter_notebooks/\"\n",
    "os.chdir(path)\n",
    "\n",
    "##### joint-boxplot a performance statistic of a trading strategy over different values of the fixed/variable transaction cost with hue = loss function\n",
    "def joint_plot( algo = 'LGBM_SPY_all_vars',\n",
    "                        loss_fns = ['CE', 'Brier', 'Boost', 'As1', 'As2'],\n",
    "                        score_fn = 'AUC',\n",
    "                        init_wealth = 1000,\n",
    "                        invest_window = 100,\n",
    "                        use_strategy = 'fixed_trans_cost',\n",
    "                        trans_costs = [0.05, 0.5],\n",
    "                        perf_stats_dict = {  'Average Number of Trades': 'average_number_of_trades',\n",
    "                                                        'Percentage of Winning Trades': 'percentage_of_winning_trades',\t\n",
    "                                                        'Largest Simple Return':   'largest_raw_return',\t\n",
    "                                                        'Smallest Simple Return':    'smallest_raw_return',\t\n",
    "                                                        'Ratio of Average Winning Trade to Average Losing Trade': 'ratio_win_loss',\t\n",
    "                                                        'Maximum Number of Consecutive Winners': 'max_number_of_consecutive_winners',\t\n",
    "                                                        'Maximum Number of Consecutive Losers':    'max_number_of_consecutive_losers', \n",
    "                                                        'Annualized Excess Return':    'annualized_excess_return',\t\n",
    "                                                        'Annualized Standard Deviation':    'annualized_standard_deviation',\t\n",
    "                                                        'Maximum Drawdown':   'max_drawdown',\t\n",
    "                                                        'Schwager\\'s Gain to Pain Ratio': 'Schwager_gain-to-pain_ratio',\t\n",
    "                                                        'Calmar Ratio':  'Calmar_ratio',\t\n",
    "                                                        'Sharpe Ratio':    'Sharpe_ratio',\t\n",
    "                                                        'Sortino Ratio': 'Sortino_ratio',\n",
    "                                                        'CECPP': 'cecpp',\n",
    "                                                        'Morningstar\\'s risk-adjusted rating': 'mrar'}):\n",
    "    ''' Joint-boxplot a performance statistic of a trading strategy over different values of the fixed/variable transaction cost with hue = loss function\n",
    "     INPUT\n",
    "        algo: a ML algorithm used to forecast\n",
    "        loss_fns: a list of loss functions used to train the model\n",
    "        score_fn: a scoring function used to cross validate the model\n",
    "        init_wealth: an initial wealth used to invest\n",
    "        invest_window: an investment horizon\n",
    "        use_strategy: the trading strategy using fixed/variable transaction costs\n",
    "        trans_costs: a list of transaction costs (i.e., fixed_trans_costs = [0.05, 0.1, 0.5, 1.0] for the fixed cost strategy \n",
    "                                                                            and  variable_trans_costs = [0.0005, 0.001, 0.005, 0.01] for the variable cost strategy)\n",
    "        perf_stats_dict: a dictionary of performance statistics\n",
    "    OUTPUT\n",
    "        Matplotlib graphs\n",
    "    '''    \n",
    "    out_dir = f'../Results/{algo}/graphs'\n",
    "    if not os.path.exists( out_dir ):\n",
    "    # create the directory if it does not exist .\n",
    "        os.makedirs( out_dir )\n",
    "\n",
    "    # import data into dataframes\n",
    "    list_dfs = [[] for _ in np.arange( len(loss_fns) )]\n",
    "\n",
    "    try:\n",
    "        for i in np.arange( len(loss_fns) ):\n",
    "            for j in np.arange( len(trans_costs) ):\n",
    "                performance_df = pd.read_csv(f'../Results/{algo}/loss_fn={loss_fns[i]}/score_fn={score_fn}/performance/' \\\n",
    "                                                                        f'performance_hper_{invest_window}_init_wealth_{init_wealth}_{use_strategy}_{trans_costs[j]}.csv', \\\n",
    "                                                                        engine = 'python', encoding='utf-8', skipinitialspace=True, sep = ',', parse_dates=['start_date', 'end_date'], index_col = 'end_date')\n",
    "                performance_df.drop(columns = ['start_date', 'ratio_profit_over_total_loss',  'annualized_return', 'annualized_return_bh'], axis = 1, inplace = True)\n",
    "                # # scale down the values of the Calmar ratio so that all the variables are roughly on the same scale\n",
    "                # performance_df['Calmar_ratio'] = StandardScaler(with_mean=False).fit_transform( performance_df['Calmar_ratio'].values.reshape(-1,1) )\n",
    "                # display(performance_df.head() )\n",
    "                list_dfs[i].append(performance_df)\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "\n",
    "    # melt all the dataframes to a long dataframe\n",
    "    list_metric_dfs = []\n",
    "    perf_stats_values = list(perf_stats_dict.values())\n",
    "    for i in np.arange( len(loss_fns) ):\n",
    "        for j in np.arange( len(trans_costs) ):\n",
    "            metric_df = list_dfs[i][j][perf_stats_values].reset_index(drop = False)\n",
    "            metric_melted_df = pd.melt(metric_df, id_vars = 'end_date', var_name='perf_stats', value_name='value')\n",
    "            metric_melted_df['loss_fn'] = [loss_fns[i] for _ in range( len(metric_melted_df ) )]\n",
    "            metric_melted_df['trans_cost'] = [trans_costs[j] for _ in range( len(metric_melted_df ) )]\n",
    "            list_metric_dfs.append(metric_melted_df)\n",
    "    merged_df = merged_df = pd.concat(list_metric_dfs, axis = 0)\n",
    "    # display(merged_df.head() )\n",
    "    # merged_df.to_csv(os.path.join(out_dir, 'merged_data.csv'), index=False, header = True) \n",
    "\n",
    "    perf_stats_keys = list( perf_stats_dict.keys() )\n",
    "    for i in np.arange( len(perf_stats_dict) ):\n",
    "        fig, ax = plt.subplots( figsize=(13, 8) )\n",
    "        perf_stat_df = merged_df[ merged_df['perf_stats'] == perf_stats_values[i] ]\n",
    "        # display( perf_stat_df.head() )\n",
    "        ax = sns.boxplot(x = 'trans_cost', y = 'value', hue='loss_fn', data=perf_stat_df)\n",
    "        sns.stripplot(x = 'trans_cost', y = 'value', hue='loss_fn', data=perf_stat_df, jitter=0.12, dodge=True, color='gray', size=2, alpha=0.8, ax = ax)\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.axhline(0, ls = '--', linewidth = 2, color ='red') \n",
    "        # ax.axhline(1, ls = '--', linewidth = 1, color ='red') \n",
    "        # ax.text(0, 1, \"1\", ha=\"center\", va=\"center\")\n",
    "        ax.grid(ls=':')\n",
    "        ax.legend(handles, labels[0:5], fontsize=10, loc = 'upper right', title = 'Loss functions')\n",
    "        ax.set_ylabel(perf_stats_keys[i], fontsize=15)\n",
    "        ax.set_xlabel('Transaction Cost', fontsize=15)\n",
    "        ax.tick_params(axis='x', which='major', labelsize=13, labelrotation=0)        \n",
    "        try:\n",
    "            score_word = re.search(r'^[^\\_]+(?=\\_)', score_fn, flags=re.IGNORECASE | re.VERBOSE).group()\n",
    "        except:\n",
    "            score_word = score_fn\n",
    "        out_file = f'{out_dir}/joint_boxplot_{invest_window}_init_wealth_{init_wealth}_score_fn_{score_word}_{use_strategy}_{perf_stats_values[i]}.png'\n",
    "        fig.savefig(out_file, dpi=150, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "    del perf_stat_df, merged_df, metric_df, performance_df\n",
    "    gc.collect()\n",
    "\n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    startTime = time.time()\n",
    "\n",
    "    # Define a list of algorithms employed\n",
    "    algos = ['RF_SPY_all_vars', 'RF_SPY_all_vars_plus_patterns', 'XGB_SPY_all_vars', 'XGB_SPY_all_vars_plus_patterns']\n",
    "    # algos = ['LGBM_SPY_all_vars', 'LGBM_SPY_all_vars_plus_patterns']\n",
    "\n",
    "    # Define a list of loss functions used to train a ML model\n",
    "    # loss_fns = ['CE', 'Brier', 'Boost', 'As1', 'As2']\n",
    "    loss_fns = ['CE']\n",
    "\n",
    "    # Define a list of score functions used to cross validate a ML algorithm\n",
    "    score_fns_fixed_trans_cost = ['Accuracy', 'AUC',  'Gain_to_pain_ratio_fixed_trans_cost', 'Calmar_ratio_fixed_trans_cost', \\\n",
    "                                                        'Sharpe_ratio_fixed_trans_cost',  'Sortino_ratio_fixed_trans_cost',  'CECPP_fixed_trans_cost']   \n",
    "    score_fns_variable_trans_cost = ['Accuracy', 'AUC',  'Gain_to_pain_ratio_variable_trans_cost', 'Calmar_ratio_variable_trans_cost', \\\n",
    "                                                            'Sharpe_ratio_variable_trans_cost', 'Sortino_ratio_variable_trans_cost', 'CECPP_variable_trans_cost']  \n",
    "\n",
    "    # Define a list of holding periods\n",
    "    invest_windows = [100, 200]\n",
    "\n",
    "    try:\n",
    "        # client = Client('tcp://localhost:8786', timeout='2s')\n",
    "        cluster = LocalCluster(n_workers=num_cores, processes=True, memory_limit='auto', threads_per_worker=1, scheduler_port=8786, dashboard_address='localhost:8787')\n",
    "        client = Client(cluster)\n",
    "    except OSError:\n",
    "        client.close()\n",
    "        cluster.close()\n",
    "        time.sleep(20)\n",
    "        cluster = LocalCluster(n_workers=num_cores, processes=True, memory_limit='auto', threads_per_worker=1, scheduler_port=8786, dashboard_address='localhost:8787')\n",
    "        client = Client(cluster)\n",
    "    print(client)\n",
    "\n",
    "    with joblib.parallel_backend('dask'):\n",
    "        job_run = joblib.Parallel(verbose=20) (joblib.delayed(joint_plot)(  algo = algo,\n",
    "                                                                                                                    loss_fns = loss_fns,\n",
    "                                                                                                                    score_fn = score_fn,\n",
    "                                                                                                                    invest_window = invest_window,\n",
    "                                                                                                                    use_strategy = 'fixed_trans_cost',\n",
    "                                                                                                                    trans_costs = [0.05, 0.5]) \\\n",
    "                                                                        for algo in algos\n",
    "                                                                            for score_fn in score_fns_fixed_trans_cost\n",
    "                                                                                for invest_window in invest_windows)\n",
    "    time.sleep(30)\n",
    "\n",
    "    with joblib.parallel_backend('dask'):\n",
    "        job_run = joblib.Parallel(verbose=20) (joblib.delayed(joint_plot)(  algo = algo,\n",
    "                                                                                                                    loss_fns = loss_fns,\n",
    "                                                                                                                    score_fn = score_fn,\n",
    "                                                                                                                    invest_window = invest_window,\n",
    "                                                                                                                    use_strategy = 'variable_trans_cost',\n",
    "                                                                                                                    trans_costs = [0.0005, 0.005]) \\\n",
    "                                                                        for algo in algos\n",
    "                                                                            for score_fn in score_fns_variable_trans_cost\n",
    "                                                                                for invest_window in invest_windows)\n",
    "\n",
    "    time.sleep(30)\n",
    "\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    print( 'The script took {} second !'.format(time.time() - startTime) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================== Compare the Performance of  a Trading Strategy based on Technical Indicators vs. Price Patterns ==================================== #\n",
    "# =========================================================================================================================================== #\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "#Gradient Color Bar Plots\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from matplotlib import colors as mcolors, path\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import joblib\n",
    "import multiprocessing\n",
    "# import dask\n",
    "# import distributed\n",
    "# dask.config.set({\"distributed.comm.timeouts.tcp\": \"100000s\", \"distributed.scheduler.allowed-failures\": 999})\n",
    "# num_cores = multiprocessing.cpu_count()\n",
    "num_cores = 30\n",
    "\n",
    "##### Set the current working directory\n",
    "path=\"e:/Copy/SCRIPTS/Forecast_Stocks/Jupyter_notebooks/\"\n",
    "os.chdir(path)\n",
    "\n",
    "##### joint-boxplot a performance statistic of a trading strategy over different loss functions for a given scoring function with hue = 'algo'\n",
    "def joint_plot1(algos = ['LGBM_SPY_all_vars', 'LGBM_SPY_all_vars_plus_patterns'],\n",
    "                        loss_fns = ['CE', 'Brier', 'Boost', 'As1', 'As2'],\n",
    "                        score_fn = 'AUC',\n",
    "                        init_wealth = 1000,\n",
    "                        invest_window = 100,\n",
    "                        use_strategy = 'fixed_trans_cost',\n",
    "                        trans_cost = 0.05,\n",
    "                        perf_stats_dict = {  'Average Number of Trades': 'average_number_of_trades',\n",
    "                                                        'Percentage of Winning Trades': 'percentage_of_winning_trades',\t\n",
    "                                                        'Largest Simple Return':   'largest_raw_return',\t\n",
    "                                                        'Smallest Simple Return':    'smallest_raw_return',\t\n",
    "                                                        'Ratio of Average Winning Trade to Average Losing Trade': 'ratio_win_loss',\t\n",
    "                                                        'Maximum Number of Consecutive Winners': 'max_number_of_consecutive_winners',\t\n",
    "                                                        'Maximum Number of Consecutive Losers':    'max_number_of_consecutive_losers', \n",
    "                                                        'Annualized Excess Return':    'annualized_excess_return',\t\n",
    "                                                        'Annualized Standard Deviation':    'annualized_standard_deviation',\t\n",
    "                                                        'Maximum Drawdown':   'max_drawdown',\t\n",
    "                                                        'Schwager\\'s Gain to Pain Ratio': 'Schwager_gain-to-pain_ratio',\t\n",
    "                                                        'Calmar Ratio':  'Calmar_ratio',\t\n",
    "                                                        'Sharpe Ratio':    'Sharpe_ratio',\t\n",
    "                                                        'Sortino Ratio': 'Sortino_ratio',\n",
    "                                                        'CECPP': 'cecpp',\n",
    "                                                        'Morningstar\\'s risk-adjusted rating': 'mrar'}):\n",
    "    ''' joint-boxplot a performance statistic of a trading strategy over different loss functions for a given scoring function with hue = 'algo'\n",
    "     INPUT\n",
    "        algos: a list of ML models used to forecast\n",
    "        loss_fns: a list of loss functions used to train the models\n",
    "        score_fn: a scoring function used to cross validate the model\n",
    "        init_wealth: an initial wealth used to invest\n",
    "        invest_window: an investment horizon\n",
    "        use_strategy: the trading strategy using fixed/variable transaction costs\n",
    "        trans_cost: a transaction cost (i.e., trans_cost = 0.05 for the fixed cost strategy and trans_cost = 0.0005 for the variable cost strategy)\n",
    "        perf_stats_dict: a dictionary of performance statistics\n",
    "    OUTPUT\n",
    "        Matplotlib graphs\n",
    "    '''    \n",
    "\n",
    "    algo_word = re.search(r'\\w+(?=\\_all)',  algos[0], flags=re.IGNORECASE | re.VERBOSE).group()\n",
    "    out_dir = f'../Results/graphs/{algo_word}'\n",
    "    if not os.path.exists( out_dir ):\n",
    "    # create the directory if it does not exist .\n",
    "        os.makedirs( out_dir )\n",
    "\n",
    "    # import data into dataframes\n",
    "    list_dfs = [[] for _ in np.arange( len(loss_fns) )]\n",
    "\n",
    "    try:\n",
    "        for i in np.arange( len(loss_fns) ):\n",
    "            for j in np.arange( len(algos) ):\n",
    "                performance_df = pd.read_csv(f'../Results/{algos[j]}/loss_fn={loss_fns[i]}/score_fn={score_fn}/performance/' \\\n",
    "                                                                        f'performance_hper_{invest_window}_init_wealth_{init_wealth}_{use_strategy}_{trans_cost}.csv', \\\n",
    "                                                                            engine = 'python', encoding='utf-8', skipinitialspace=True, sep = ',', parse_dates=['start_date', 'end_date'], index_col = 'end_date')\n",
    "                performance_df.drop(columns = ['start_date', 'ratio_profit_over_total_loss',  'annualized_return', 'annualized_return_bh'], axis = 1, inplace = True)\n",
    "                # # scale down the values of the Calmar ratio so that all the variables are roughly on the same scale\n",
    "                # performance_df['Calmar_ratio'] = StandardScaler(with_mean=False).fit_transform( performance_df['Calmar_ratio'].values.reshape(-1,1) )\n",
    "                # display(performance_df.head() )\n",
    "                list_dfs[i].append(performance_df)\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "\n",
    "    # melt all the dataframes to a long dataframe\n",
    "    list_metric_dfs = []\n",
    "    perf_stats_values = list(perf_stats_dict.values())\n",
    "    for i in np.arange( len(loss_fns) ):\n",
    "        for j in np.arange( len(algos) ):\n",
    "            metric_df = list_dfs[i][j][perf_stats_values].reset_index(drop = False)\n",
    "            metric_melted_df = pd.melt(metric_df, id_vars = 'end_date', var_name='perf_stats', value_name='value')\n",
    "            metric_melted_df['loss_fn'] = [loss_fns[i] for _ in range( len(metric_melted_df ) )]\n",
    "            metric_melted_df['predictor_set'] = [algos[j] for _ in range( len(metric_melted_df ) )]\n",
    "            list_metric_dfs.append(metric_melted_df)\n",
    "    merged_df = pd.concat(list_metric_dfs, axis = 0)\n",
    "    # display(merged_df.head() )\n",
    "    # merged_df.to_csv(os.path.join(out_dir, 'merged_data.csv'), index=False, header = True) \n",
    "\n",
    "    perf_stats_keys = list( perf_stats_dict.keys() )\n",
    "    for i in np.arange( len(perf_stats_dict) ):\n",
    "        fig, ax = plt.subplots( figsize=(13, 8) )\n",
    "        perf_stat_df = merged_df[ merged_df['perf_stats'] == perf_stats_values[i] ]\n",
    "        # display( perf_stat_df.head() )\n",
    "        ax = sns.boxplot(x = 'loss_fn', y = 'value', hue='predictor_set', data=perf_stat_df)\n",
    "        sns.stripplot(x = 'loss_fn', y = 'value', hue='predictor_set', data=perf_stat_df, jitter=0.12, dodge=True, color='gray', size=2, alpha=0.8, ax = ax)\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.axhline(0, ls = '--', linewidth = 2, color ='red') \n",
    "        # ax.axhline(1, ls = '--', linewidth = 1, color ='red') \n",
    "        # ax.text(0, 1, \"1\", ha=\"center\", va=\"center\")\n",
    "        ax.grid(ls=':')\n",
    "        # ax.legend(handles[0:5], labels[0:5], fontsize=10)\n",
    "        ax.legend(handles = handles, labels = ['Dataset I', 'Dataset II'], loc = 'upper right', title = 'Set of Predictors')\n",
    "        ax.set_ylabel(perf_stats_keys[i], fontsize=15)\n",
    "        ax.set_xlabel('Loss Function', fontsize=15)\n",
    "        ax.tick_params(axis='x', which='major', labelsize=13, labelrotation=0)        \n",
    "        \n",
    "        try:\n",
    "            score_word = re.search(r'^[^\\_]+(?=\\_)', score_fn, flags=re.IGNORECASE | re.VERBOSE).group()\n",
    "        except:\n",
    "            score_word = score_fn\n",
    "        \n",
    "        out_file = f'{out_dir}/joint_boxplot_{score_word}_{invest_window}_init_wealth_{init_wealth}_{use_strategy}_{trans_cost}_perf_metric_{perf_stats_values[i]}.png'\n",
    "        fig.savefig(out_file, dpi=150, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "    del perf_stat_df, merged_df, metric_df, performance_df\n",
    "    gc.collect()\n",
    "\n",
    "    return True\n",
    "\n",
    "##### joint-boxplot a performance statistic of a trading strategy over different scoring functions for a given loss function with hue = 'algo'\n",
    "def joint_plot2(algos = ['LGBM_SPY_all_vars', 'LGBM_SPY_all_vars_plus_patterns'],\n",
    "                        loss_fn = 'CE',\n",
    "                        score_fns_dict = {'Accuracy': 'Accuracy', 'AUC': 'AUC',  'Schwager\\'s gain/pain ratio': 'Gain_to_pain_ratio_fixed_trans_cost', \\\n",
    "                                                    'Calmar ratio': 'Calmar_ratio_fixed_trans_cost', 'Sharpe ratio': 'Sharpe_ratio_fixed_trans_cost', \\\n",
    "                                                    'Sortino ratio': 'Sortino_ratio_fixed_trans_cost',  'CECPP': 'CECPP_fixed_trans_cost'},\n",
    "                        init_wealth = 1000,\n",
    "                        invest_window = 100,\n",
    "                        trans_cost = 0.05,\n",
    "                        perf_stats_dict = {  'Average Number of Trades': 'average_number_of_trades',\n",
    "                                                        'Percentage of Winning Trades': 'percentage_of_winning_trades',\t\n",
    "                                                        'Largest Simple Return':   'largest_raw_return',\t\n",
    "                                                        'Smallest Simple Return':    'smallest_raw_return',\t\n",
    "                                                        'Ratio of Average Winning Trade to Average Losing Trade': 'ratio_win_loss',\t\n",
    "                                                        'Maximum Number of Consecutive Winners': 'max_number_of_consecutive_winners',\t\n",
    "                                                        'Maximum Number of Consecutive Losers':    'max_number_of_consecutive_losers', \n",
    "                                                        'Annualized Excess Return':    'annualized_excess_return',\t\n",
    "                                                        'Annualized Standard Deviation':    'annualized_standard_deviation',\t\n",
    "                                                        'Maximum Drawdown':   'max_drawdown',\t\n",
    "                                                        'Schwager\\'s Gain to Pain Ratio': 'Schwager_gain-to-pain_ratio',\t\n",
    "                                                        'Calmar Ratio':  'Calmar_ratio',\t\n",
    "                                                        'Sharpe Ratio':    'Sharpe_ratio',\t\n",
    "                                                        'Sortino Ratio': 'Sortino_ratio',\n",
    "                                                        'CECPP': 'cecpp',\n",
    "                                                        'Morningstar\\'s risk-adjusted rating': 'mrar'}):\n",
    "    ''' Joint-boxplot a performance statistic of a trading strategy over different scoring functions for a given loss function with hue = 'algo'.\n",
    "     INPUT\n",
    "        algos: a list of ML models used to forecast\n",
    "        loss_fns_dict: a loss function used to train the models\n",
    "        score_fns_dict: a dictionary of scoring functions used for cross validation\n",
    "        init_wealth: an initial wealth used to invest\n",
    "        invest_window: an investment horizon\n",
    "        trans_cost: a transaction cost (i.e., trans_cost = 0.05 for the fixed cost strategy and trans_costs = 0.0005 for the variable cost strategy)\n",
    "        perf_stats_dict: a dictionary of performance statistics\n",
    "    OUTPUT\n",
    "        Matplotlib graphs\n",
    "    '''    \n",
    "\n",
    "    algo_word = re.search(r'\\w+(?=\\_all)',  algos[0], flags=re.IGNORECASE | re.VERBOSE).group()\n",
    "    out_dir = f'../Results/graphs/{algo_word}'\n",
    "    if not os.path.exists( out_dir ):\n",
    "    # create the directory if it does not exist .\n",
    "        os.makedirs( out_dir )\n",
    "\n",
    "    score_fns_keys = list(score_fns_dict.keys())\n",
    "    score_fns_values = list(score_fns_dict.values())\n",
    "    try:\n",
    "        use_strategy = re.search(r'(?<=ratio\\_)\\w+', score_fns_values[2], flags=re.IGNORECASE | re.VERBOSE).group()\n",
    "    except:\n",
    "        try:\n",
    "            use_strategy = re.search(r'(?<=ratio\\_)\\w+', score_fns_values[0], flags=re.IGNORECASE | re.VERBOSE).group()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # import data into dataframes\n",
    "    list_dfs = [[] for _ in np.arange( len(score_fns_dict) )]\n",
    "\n",
    "    try:\n",
    "        for i in np.arange( len(score_fns_dict) ):\n",
    "            for j in np.arange( len(algos) ):\n",
    "                performance_df = pd.read_csv(f'../Results/{algos[j]}/loss_fn={loss_fn}/score_fn={score_fns_values[i]}/performance/' \\\n",
    "                                                                        f'performance_hper_{invest_window}_init_wealth_{init_wealth}_{use_strategy}_{trans_cost}.csv', \\\n",
    "                                                                            engine = 'python', encoding='utf-8', skipinitialspace=True, sep = ',', parse_dates=['start_date', 'end_date'], index_col = 'end_date')\n",
    "                performance_df.drop(columns = ['start_date', 'ratio_profit_over_total_loss',  'annualized_return', 'annualized_return_bh'], axis = 1, inplace = True)\n",
    "                # # scale down the values of the Calmar ratio so that all the variables are roughly on the same scale\n",
    "                # performance_df['Calmar_ratio'] = StandardScaler(with_mean=False).fit_transform( performance_df['Calmar_ratio'].values.reshape(-1,1) )\n",
    "                # display(performance_df.head() )\n",
    "                list_dfs[i].append(performance_df)\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "\n",
    "    # melt all the dataframes to a long dataframe\n",
    "    list_metric_dfs = []\n",
    "    perf_stats_values = list(perf_stats_dict.values())\n",
    "    for i in np.arange( len(score_fns_dict) ):\n",
    "        for j in np.arange( len(algos) ):\n",
    "            metric_df = list_dfs[i][j][perf_stats_values].reset_index(drop = False)\n",
    "            metric_melted_df = pd.melt(metric_df, id_vars = 'end_date', var_name='perf_stats', value_name='value')\n",
    "            metric_melted_df['score_fn'] = [score_fns_keys[i] for _ in range( len(metric_melted_df ) )]\n",
    "            metric_melted_df['predictor_set'] = [algos[j] for _ in range( len(metric_melted_df ) )]\n",
    "            list_metric_dfs.append(metric_melted_df)\n",
    "    merged_df = pd.concat(list_metric_dfs, axis = 0)\n",
    "    # display(merged_df.head() )\n",
    "    # merged_df.to_csv(os.path.join(out_dir, 'merged_data.csv'), index=False, header = True) \n",
    "\n",
    "    perf_stats_keys = list( perf_stats_dict.keys() )\n",
    "    for i in np.arange( len(perf_stats_dict) ):\n",
    "        fig, ax = plt.subplots( figsize=(13, 8) )\n",
    "        perf_stat_df = merged_df[ merged_df['perf_stats'] == perf_stats_values[i] ]\n",
    "        # display( perf_stat_df.head() )\n",
    "        ax = sns.boxplot(x = 'score_fn', y = 'value', hue='predictor_set', data=perf_stat_df)\n",
    "        sns.stripplot(x = 'score_fn', y = 'value', hue='predictor_set', data=perf_stat_df, jitter=0.12, dodge=True, color='gray', size=2, alpha=0.8, ax = ax)\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.axhline(0, ls = '--', linewidth = 2, color ='red') \n",
    "        # ax.axhline(1, ls = '--', linewidth = 1, color ='red') \n",
    "        # ax.text(0, 1, \"1\", ha=\"center\", va=\"center\")\n",
    "        ax.grid(ls=':')\n",
    "        # ax.legend(handles[0:5], labels[0:5], fontsize=10)\n",
    "        ax.legend(handles = handles, labels = ['Dataset I', 'Dataset II'], loc = 'upper right', title = 'Set of Predictors')\n",
    "        ax.set_ylabel(perf_stats_keys[i], fontsize=15)\n",
    "        ax.set_xlabel('Scoring Function', fontsize=15)\n",
    "        ax.tick_params(axis='x', which='major', labelsize=10, labelrotation=10)        \n",
    "        \n",
    "        out_file = f'{out_dir}/joint_boxplot_{loss_fn}_{invest_window}_init_wealth_{init_wealth}_{use_strategy}_{trans_cost}_perf_metric_{perf_stats_values[i]}.png'\n",
    "        fig.savefig(out_file, dpi=150, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "    del perf_stat_df, merged_df, metric_df, performance_df\n",
    "    gc.collect()\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "##### joint-boxplot a performance statistic of a trading strategy over different scoring functions for a given loss function with hue = four different ML models\n",
    "def joint_plot3(algos = ['RF_SPY_all_vars', 'RF_SPY_all_vars_plus_patterns', 'RF_RW_all_vars', 'RF_RW_all_vars_plus_patterns'],\n",
    "                        loss_fn = 'CE',\n",
    "                        score_fns_dict = {'Accuracy': 'Accuracy', 'AUC': 'AUC',  'Schwager\\'s gain/pain ratio': 'Gain_to_pain_ratio_fixed_trans_cost', \\\n",
    "                                                        'Calmar ratio': 'Calmar_ratio_fixed_trans_cost', 'Sharpe ratio': 'Sharpe_ratio_fixed_trans_cost', \\\n",
    "                                                        'Sortino ratio': 'Sortino_ratio_fixed_trans_cost',  'CECPP': 'CECPP_fixed_trans_cost'},\n",
    "                        init_wealth = 1000,\n",
    "                        invest_window = 100,\n",
    "                        trans_cost = 0.05,\n",
    "                        perf_stats_dict = {  'Average Number of Trades': 'average_number_of_trades',\n",
    "                                                        'Percentage of Winning Trades': 'percentage_of_winning_trades',\t\n",
    "                                                        'Largest Simple Return':   'largest_raw_return',\t\n",
    "                                                        'Smallest Simple Return':    'smallest_raw_return',\t\n",
    "                                                        'Ratio of Average Winning Trade to Average Losing Trade': 'ratio_win_loss',\t\n",
    "                                                        'Maximum Number of Consecutive Winners': 'max_number_of_consecutive_winners',\t\n",
    "                                                        'Maximum Number of Consecutive Losers':    'max_number_of_consecutive_losers', \n",
    "                                                        'Annualized Excess Return':    'annualized_excess_return',\t\n",
    "                                                        'Risk-Adjusted Annualized Excess Return': 'risk_adj_annualized_excess_return',\n",
    "                                                        'Annualized Standard Deviation':    'annualized_standard_deviation',\t\n",
    "                                                        'Maximum Drawdown':   'max_drawdown',\t\n",
    "                                                        'Schwager\\'s Gain to Pain Ratio': 'Schwager_gain-to-pain_ratio',\t\n",
    "                                                        'Calmar Ratio':  'Calmar_ratio',\t\n",
    "                                                        'Sharpe Ratio':    'Sharpe_ratio',\t\n",
    "                                                        'Sortino Ratio': 'Sortino_ratio',\n",
    "                                                        'CECPP': 'cecpp',\n",
    "                                                        'Morningstar\\'s risk-adjusted rating': 'mrar'}):\n",
    "    ''' Joint-boxplot a performance statistic of a trading strategy over different scoring functions for a given loss function with hue = 'algos'.\n",
    "     INPUT\n",
    "        algos: a list of ML models used to forecast\n",
    "        loss_fns_dict: a loss function used to train the models\n",
    "        score_fns_dict: a dictionary of scoring functions used for cross validation\n",
    "        init_wealth: an initial wealth used to invest\n",
    "        invest_window: an investment horizon\n",
    "        trans_cost: a transaction cost (i.e., trans_cost = 0.05 for the fixed cost strategy and trans_costs = 0.0005 for the variable cost strategy)\n",
    "        perf_stats_dict: a dictionary of performance statistics\n",
    "    OUTPUT\n",
    "        Matplotlib graphs\n",
    "    '''    \n",
    "\n",
    "    algo_word1 = re.search(r'\\w+(?=\\_all)',  algos[0], flags=re.IGNORECASE | re.VERBOSE).group()\n",
    "    algo_word2 = re.search(r'\\w+(?=\\_all)',  algos[2], flags=re.IGNORECASE | re.VERBOSE).group()\n",
    "    out_dir = f'../Results/graphs/{algo_word1}_and_{algo_word2}'\n",
    "    if not os.path.exists( out_dir ):\n",
    "    # create the directory if it does not exist .\n",
    "        os.makedirs( out_dir )\n",
    "\n",
    "    score_fns_keys = list(score_fns_dict.keys())\n",
    "    score_fns_values = list(score_fns_dict.values())\n",
    "    try:\n",
    "        use_strategy = re.search(r'(?<=ratio\\_)\\w+', score_fns_values[2], flags=re.IGNORECASE | re.VERBOSE).group()\n",
    "    except:\n",
    "        try:\n",
    "            use_strategy = re.search(r'(?<=ratio\\_)\\w+', score_fns_values[0], flags=re.IGNORECASE | re.VERBOSE).group()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # import data into dataframes\n",
    "    list_dfs = [[] for _ in np.arange( len(score_fns_dict) )]\n",
    "\n",
    "    try:\n",
    "        for i in np.arange( len(score_fns_dict) ):\n",
    "            for j in np.arange( len(algos) ):\n",
    "                performance_df = pd.read_csv(f'../Results/{algos[j]}/loss_fn={loss_fn}/score_fn={score_fns_values[i]}/performance/' \\\n",
    "                                                                        f'performance_hper_{invest_window}_init_wealth_{init_wealth}_{use_strategy}_{trans_cost}.csv', \\\n",
    "                                                                            engine = 'python', encoding='utf-8', skipinitialspace=True, sep = ',', parse_dates=['start_date', 'end_date'], index_col = 'end_date')\n",
    "                performance_df.drop(columns = ['start_date', 'ratio_profit_over_total_loss',  'annualized_return', 'annualized_return_bh'], axis = 1, inplace = True)\n",
    "                # # scale down the values of the Calmar ratio so that all the variables are roughly on the same scale\n",
    "                # performance_df['Calmar_ratio'] = StandardScaler(with_mean=False).fit_transform( performance_df['Calmar_ratio'].values.reshape(-1,1) )\n",
    "                performance_df['risk_adj_annualized_excess_return'] = performance_df['annualized_excess_return'] / performance_df['annualized_standard_deviation']\n",
    "                # display(performance_df.head() )\n",
    "                list_dfs[i].append(performance_df)\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "\n",
    "    # melt all the dataframes to a long dataframe\n",
    "    list_metric_dfs = []\n",
    "    perf_stats_values = list(perf_stats_dict.values())\n",
    "    for i in np.arange( len(score_fns_dict) ):\n",
    "        for j in np.arange( len(algos) ):\n",
    "            metric_df = list_dfs[i][j][perf_stats_values].reset_index(drop = False)\n",
    "            metric_melted_df = pd.melt(metric_df, id_vars = 'end_date', var_name='perf_stats', value_name='value')\n",
    "            metric_melted_df['score_fn'] = [score_fns_keys[i] for _ in range( len(metric_melted_df ) )]\n",
    "            metric_melted_df['predictor_set'] = [algos[j] for _ in range( len(metric_melted_df ) )]\n",
    "            list_metric_dfs.append(metric_melted_df)\n",
    "    merged_df = pd.concat(list_metric_dfs, axis = 0)\n",
    "    # display(merged_df.head() )\n",
    "    # merged_df.to_csv(os.path.join(out_dir, 'merged_data.csv'), index=False, header = True) \n",
    "    \n",
    "    perf_stats_keys = list( perf_stats_dict.keys() )\n",
    "    for i in np.arange( len(perf_stats_dict) ):\n",
    "        fig, ax = plt.subplots( figsize=(13, 8) )\n",
    "        perf_stat_df = merged_df[ merged_df['perf_stats'] == perf_stats_values[i] ]\n",
    "        # display( perf_stat_df.head() )\n",
    "        ax = sns.boxplot(x = 'score_fn', y = 'value', hue='predictor_set', data=perf_stat_df)\n",
    "        sns.stripplot(x = 'score_fn', y = 'value', hue='predictor_set', data=perf_stat_df, jitter=0.12, dodge=True, color='gray', size=2, alpha=0.8, ax = ax)\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.axhline(0, ls = '--', linewidth = 2, color ='red') \n",
    "        # ax.axhline(1, ls = '--', linewidth = 1, color ='red') \n",
    "        # ax.text(0, 1, \"1\", ha=\"center\", va=\"center\")\n",
    "        ax.grid(ls=':')\n",
    "        # ax.legend(handles[0:5], labels[0:5], fontsize=10)\n",
    "        ax.legend(handles = handles, labels = ['SPY: Dataset I', 'SPY: Dataset II', 'RW: Dataset I', 'RW: Dataset II'], loc = 'upper right', title = 'Data & Predictors')\n",
    "        ax.set_ylabel(perf_stats_keys[i], fontsize=15)\n",
    "        ax.set_xlabel('Scoring Function', fontsize=15)\n",
    "        ax.tick_params(axis='x', which='major', labelsize=10, labelrotation=10)        \n",
    "        \n",
    "        out_file = f'{out_dir}/joint_boxplot_{loss_fn}_{invest_window}_init_wealth_{init_wealth}_{use_strategy}_{trans_cost}_perf_metric_{perf_stats_values[i]}.png'\n",
    "        fig.savefig(out_file, dpi=150, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "    del perf_stat_df, merged_df, metric_df, performance_df\n",
    "    gc.collect()\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    startTime = time.time()\n",
    "\n",
    "    # Define a list of algorithms employed\n",
    "    # algos = ['RF_SPY_all_vars', 'RF_SPY_all_vars_plus_patterns']\n",
    "    # algos = ['XGB_SPY_all_vars', 'XGB_SPY_all_vars_plus_patterns']\n",
    "    # algos = ['LGBM_SPY_all_vars', 'LGBM_SPY_all_vars_plus_patterns']\n",
    "    \n",
    "    algos = ['RF_SPY_all_vars_plus_patterns', 'RF_RW_all_vars_plus_patterns']\n",
    "\n",
    "    # Define a list of loss functions used to train a ML model\n",
    "    # loss_fns = ['CE', 'Brier', 'Boost', 'As1', 'As2']\n",
    "    loss_fns = ['CE']\n",
    "\n",
    "    # Define a list of score functions used to cross validate a ML algorithm\n",
    "    score_fns_fixed_trans_cost_dict = {'Accuracy': 'Accuracy', 'AUC': 'AUC',  'Schwager\\'s gain/pain ratio': 'Gain_to_pain_ratio_fixed_trans_cost', \\\n",
    "                                                                'Calmar ratio': 'Calmar_ratio_fixed_trans_cost', 'Sharpe ratio': 'Sharpe_ratio_fixed_trans_cost', \\\n",
    "                                                                'Sortino ratio': 'Sortino_ratio_fixed_trans_cost',  'CECPP': 'CECPP_fixed_trans_cost'}\n",
    "    \n",
    "    score_fns_variable_trans_cost_dict = {'Accuracy': 'Accuracy', 'AUC': 'AUC',  'Schwager\\'s gain/pain ratio': 'Gain_to_pain_ratio_variable_trans_cost', \\\n",
    "                                                                    'Calmar ratio': 'Calmar_ratio_variable_trans_cost', 'Sharpe ratio': 'Sharpe_ratio_variable_trans_cost', \\\n",
    "                                                                    'Sortino ratio': 'Sortino_ratio_variable_trans_cost',  'CECPP': 'CECPP_variable_trans_cost'}  \n",
    "\n",
    "    # Define a list of holding periods\n",
    "    invest_windows = [100, 200]\n",
    "    \n",
    "    # joint_plot3( score_fns_dict = score_fns_fixed_trans_cost_dict)\n",
    "    \n",
    "    try:\n",
    "        # client = Client('tcp://localhost:8786', timeout='2s')\n",
    "        cluster = LocalCluster(n_workers=num_cores, processes=True, memory_limit='auto', threads_per_worker=1, scheduler_port=8786, dashboard_address='localhost:8787')\n",
    "        client = Client(cluster)\n",
    "    except OSError:\n",
    "        client.close()\n",
    "        cluster.close()\n",
    "        time.sleep(20)\n",
    "        cluster = LocalCluster(n_workers=num_cores, processes=True, memory_limit='auto', threads_per_worker=1, scheduler_port=8786, dashboard_address='localhost:8787')\n",
    "        client = Client(cluster)\n",
    "    print(client)\n",
    "\n",
    "    # # joint-boxplot a performance statistic of a trading strategy over different loss functions for a given scoring function with hue = 'algo'\n",
    "    # if algos[0] == 'LGBM_SPY_all_vars':\n",
    "    #     with joblib.parallel_backend('dask'):\n",
    "    #         job_run = joblib.Parallel(verbose=20) (joblib.delayed(joint_plot1)( score_fn = score_fn, \n",
    "    #                                                                                                                     invest_window = invest_window, \n",
    "    #                                                                                                                     use_strategy = 'fixed_trans_cost', \n",
    "    #                                                                                                                     trans_cost = 0.05) \\\n",
    "    #                                                                             for score_fn in list( score_fns_fixed_trans_cost_dict.values() )\n",
    "    #                                                                                 for invest_window in invest_windows)\n",
    "    #     time.sleep(30)\n",
    "        \n",
    "    #     with joblib.parallel_backend('dask'):\n",
    "    #         job_run = joblib.Parallel(verbose=20) (joblib.delayed(joint_plot1)( score_fn = score_fn, \n",
    "    #                                                                                                                     invest_window = invest_window, \n",
    "    #                                                                                                                     use_strategy = 'variable_trans_cost', \n",
    "    #                                                                                                                     trans_cost = 0.0005) \\\n",
    "    #                                                                             for score_fn in list( score_fns_variable_trans_cost_dict.values() )\n",
    "    #                                                                                 for invest_window in invest_windows)\n",
    "            \n",
    "    #     time.sleep(30)\n",
    "    # else:\n",
    "    #     pass\n",
    "    \n",
    "    # # joint-boxplot a performance statistic of a trading strategy over different scoring functions for a given loss function with hue = 'algo'\n",
    "    # with joblib.parallel_backend('dask'):\n",
    "    #     job_run = joblib.Parallel(verbose=20) (joblib.delayed(joint_plot2)( algos = algos, \n",
    "    #                                                                                                                 loss_fn = loss_fn, \n",
    "    #                                                                                                                 score_fns_dict = score_fns_fixed_trans_cost_dict, \n",
    "    #                                                                                                                 invest_window = invest_window, \n",
    "    #                                                                                                                 trans_cost = 0.05) \\\n",
    "    #                                                                         for loss_fn in loss_fns\n",
    "    #                                                                             for invest_window in invest_windows)\n",
    "    # time.sleep(30)\n",
    "    \n",
    "    # with joblib.parallel_backend('dask'):\n",
    "    #     job_run = joblib.Parallel(verbose=20) (joblib.delayed(joint_plot2)( algos = algos, \n",
    "    #                                                                                                                 loss_fn = loss_fn, \n",
    "    #                                                                                                                 score_fns_dict = score_fns_variable_trans_cost_dict, \n",
    "    #                                                                                                                 invest_window = invest_window, \n",
    "    #                                                                                                                 trans_cost = 0.0005) \\\n",
    "    #                                                                         for loss_fn in loss_fns\n",
    "    #                                                                             for invest_window in invest_windows)\n",
    "\n",
    "    # time.sleep(30)\n",
    "    \n",
    "    ##### joint-boxplot a performance statistic of a trading strategy over different scoring functions for a given loss function with hue = four different ML models\n",
    "    with joblib.parallel_backend('dask'):\n",
    "        job_run = joblib.Parallel(verbose=20) (joblib.delayed(joint_plot3)( algos = ['RF_SPY_all_vars', 'RF_SPY_all_vars_plus_patterns', 'RF_RW_all_vars', 'RF_RW_all_vars_plus_patterns'],\n",
    "                                                                                                                    loss_fn = loss_fn, \n",
    "                                                                                                                    score_fns_dict = score_fns_fixed_trans_cost_dict, \n",
    "                                                                                                                    invest_window = invest_window, \n",
    "                                                                                                                    trans_cost = 0.05) \\\n",
    "                                                                            for loss_fn in loss_fns\n",
    "                                                                                for invest_window in invest_windows)\n",
    "    time.sleep(30)\n",
    "\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "    \n",
    "\n",
    "    \n",
    "    print( 'The script took {} second !'.format(time.time() - startTime) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================= Plot Reality Check (RC) p-values ================================================================= #\n",
    "# =========================================================================================================================================== #\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from cycler import cycler\n",
    "\n",
    "# ------------------------------------------------------------------------------- Plot the RC p-values from RF trained on SPY ------------------------------------------------------------------------------------------------- #\n",
    "# ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- #\n",
    "# # Set path to the RC p-values generated by RF trained on SPY\n",
    "# folder_path = Path(f'../Results/bootstrap/RF_SPY/')\n",
    "# column_mapping = {  'RF_SPY_all_vars_CE_Accuracy': 'Dataset I: Accuracy',\n",
    "#                                     'RF_SPY_all_vars_CE_AUC': 'Dataset I: AUC',\n",
    "#                                     'RF_SPY_all_vars_CE_Gain_to_pain_ratio_fixed_trans_cost': 'Dataset I: Schwager\\'s gain/pain ratio',\n",
    "#                                     'RF_SPY_all_vars_CE_Calmar_ratio_fixed_trans_cost': 'Dataset I: Calmar ratio',\n",
    "#                                     'RF_SPY_all_vars_CE_Sharpe_ratio_fixed_trans_cost': 'Dataset I: Sharpe ratio',\n",
    "#                                     'RF_SPY_all_vars_CE_Sortino_ratio_fixed_trans_cost': 'Dataset I: Sortino ratio',\n",
    "#                                     'RF_SPY_all_vars_CE_CECPP_fixed_trans_cost': 'Dataset I: CECPP',\n",
    "#                                     'RF_SPY_all_vars_plus_patterns_CE_Accuracy': 'Dataset II: Accuracy',\n",
    "#                                     'RF_SPY_all_vars_plus_patterns_CE_AUC': 'Dataset II: AUC',\n",
    "#                                     'RF_SPY_all_vars_plus_patterns_CE_Gain_to_pain_ratio_fixed_trans_cost':  'Dataset II: Schwager\\'s gain/pain ratio',\n",
    "#                                     'RF_SPY_all_vars_plus_patterns_CE_Calmar_ratio_fixed_trans_cost': 'Dataset II: Calmar ratio',\n",
    "#                                     'RF_SPY_all_vars_plus_patterns_CE_Sharpe_ratio_fixed_trans_cost': 'Dataset II: Sharpe ratio',\n",
    "#                                     'RF_SPY_all_vars_plus_patterns_CE_Sortino_ratio_fixed_trans_cost': 'Dataset II: Sortino ratio',\n",
    "#                                     'RF_SPY_all_vars_plus_patterns_CE_CECPP_fixed_trans_cost': 'Dataset II: CECPP'\n",
    "#                                 }\n",
    "\n",
    "# # Read all RC p-values to a dataframe\n",
    "# file_path = folder_path.joinpath('all_p_values.csv')\n",
    "# p_values_df = pd.read_csv(file_path, encoding='utf-8', sep = ',', low_memory=False, header = 0, skiprows = 0, skipinitialspace=True)\n",
    "# p_values_df = p_values_df.rename(columns = column_mapping)\n",
    "# display(p_values_df.shape )\n",
    "\n",
    "# fig, ax = plt.subplots( figsize=(13, 8) )\n",
    "# ax.set_prop_cycle(cycler('color', ['r', 'g', 'b', 'y']) * cycler('marker', ['o', 'v', '^', '>'])) #  cycler('linestyle', ['-', '--', ':', '-.']) \n",
    "# p_values_df.plot(kind='line', ax = ax)\n",
    "\n",
    "# # set line widths, styles, and markers\n",
    "# linewidths = [(i+2)/4. for i in range(p_values_df.shape[1])]\n",
    "# for i, line in enumerate(ax.get_lines()):\n",
    "#     line.set_linewidth(linewidths[i])\n",
    "# #    line.set_linestyle(lines[i])\n",
    "# #     line.set_marker(markers[i])\n",
    "\n",
    "# # add a horizontal line\n",
    "# ax.axhline(y = 0.05, linestyle='--', linewidth = 2, color ='black')\n",
    "# ax.text(-1.1, 0.05, \"0.05\")\n",
    "# ax.grid(ls=':')\n",
    "# ax.legend(fontsize=10, loc='upper center', bbox_to_anchor=(0.5, -0.0), ncol = 2)\n",
    "# ax.set_ylabel('RC p-value', fontsize=15)\n",
    "# fig.savefig(folder_path.joinpath('rc_p_values.png'), dpi=150, bbox_inches=\"tight\")\n",
    "\n",
    "# ---------------------------------------------------------------------------------------- Plot the RC p-values from LGBM trained on SPY ------------------------------------------------------------------------------------- #\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ #\n",
    "\n",
    "# Set path to the RC p-values generated by LGBM trained on SPY\n",
    "folder_path = Path(f'../Results/bootstrap/LGBM_SPY/')\n",
    "column_mapping = {  'LGBM_SPY_all_vars_CE_Accuracy': 'Dataset I (loss: $CE$, score: Accuracy)',\n",
    "                                    'LGBM_SPY_all_vars_CE_AUC': 'Dataset I (loss: $CE$, score: AUC)',\n",
    "                                    'LGBM_SPY_all_vars_CE_Gain_to_pain_ratio_fixed_trans_cost': 'Dataset I (loss: $CE$, score: Schwager\\'s gain/pain ratio)',\n",
    "                                    'LGBM_SPY_all_vars_CE_Calmar_ratio_fixed_trans_cost':  'Dataset I (loss: $CE$, score: Calmar ratio)',\t\n",
    "                                    'LGBM_SPY_all_vars_CE_Sharpe_ratio_fixed_trans_cost':  'Dataset I (loss: $CE$, score: Sharpe ratio)',\t\n",
    "                                    'LGBM_SPY_all_vars_CE_Sortino_ratio_fixed_trans_cost':  'Dataset I (loss: $CE$, score: Sortino ratio)',\n",
    "                                    'LGBM_SPY_all_vars_CE_CECPP_fixed_trans_cost':  'Dataset I (loss: $CE$, score: CECPP)',\n",
    "                                    'LGBM_SPY_all_vars_Brier_Accuracy':  'Dataset I (loss: Brier, score: Accuracy)',\t\n",
    "                                    'LGBM_SPY_all_vars_Brier_AUC':  'Dataset I (loss: Brier, score: AUC)',\t\n",
    "                                    'LGBM_SPY_all_vars_Brier_Gain_to_pain_ratio_fixed_trans_cost':  'Dataset I (loss: Brier, score: Schwager\\'s gain/pain ratio)',\n",
    "                                    'LGBM_SPY_all_vars_Brier_Calmar_ratio_fixed_trans_cost':  'Dataset I (loss: Brier, score: Calmar ratio)',\n",
    "                                    'LGBM_SPY_all_vars_Brier_Sharpe_ratio_fixed_trans_cost':  'Dataset I (loss: Brier, score: Sharpe ratio)',\n",
    "                                    'LGBM_SPY_all_vars_Brier_Sortino_ratio_fixed_trans_cost':  'Dataset I (loss: Brier, score: Sortino ratio)',\n",
    "                                    'LGBM_SPY_all_vars_Brier_CECPP_fixed_trans_cost':  'Dataset I (loss: Brier, score: CECPP)',\n",
    "                                    'LGBM_SPY_all_vars_Boost_Accuracy':  'Dataset I (loss: Boost, score: Accuracy)',\n",
    "                                    'LGBM_SPY_all_vars_Boost_AUC':  'Dataset I (loss: Boost, score: AUC)',\t\n",
    "                                    'LGBM_SPY_all_vars_Boost_Gain_to_pain_ratio_fixed_trans_cost':  'Dataset I (loss: Boost, score: Schwager\\'s gain/pain ratio)',\n",
    "                                    'LGBM_SPY_all_vars_Boost_Calmar_ratio_fixed_trans_cost':  'Dataset I (loss: Boost, score: Calmar ratio)',\n",
    "                                    'LGBM_SPY_all_vars_Boost_Sharpe_ratio_fixed_trans_cost':  'Dataset I (loss: Boost, score: Sharpe ratio)',\n",
    "                                    'LGBM_SPY_all_vars_Boost_Sortino_ratio_fixed_trans_cost':  'Dataset I (loss: Boost, score: Sortino ratio)',\n",
    "                                    'LGBM_SPY_all_vars_Boost_CECPP_fixed_trans_cost':  'Dataset I (loss: Boost, score: CECPP)',\n",
    "                                    'LGBM_SPY_all_vars_As1_Accuracy':  'Dataset I (loss: As1, score: Accuracy)',\n",
    "                                    'LGBM_SPY_all_vars_As1_AUC':  'Dataset I (loss: As1, score: AUC)',\t\n",
    "                                    'LGBM_SPY_all_vars_As1_Gain_to_pain_ratio_fixed_trans_cost':  'Dataset I (loss: As1, score: Schwager\\'s gain/pain ratio)',\t\n",
    "                                    'LGBM_SPY_all_vars_As1_Calmar_ratio_fixed_trans_cost':  'Dataset I (loss: As1, score: Calmar ratio)',\n",
    "                                    'LGBM_SPY_all_vars_As1_Sharpe_ratio_fixed_trans_cost': 'Dataset I (loss: As1, score: Sharpe ratio)',\t\n",
    "                                    'LGBM_SPY_all_vars_As1_Sortino_ratio_fixed_trans_cost': 'Dataset I (loss: As1, score: Sortino ratio)',\n",
    "                                    'LGBM_SPY_all_vars_As1_CECPP_fixed_trans_cost': 'Dataset I (loss: As1, score: CECPP)',\n",
    "                                    'LGBM_SPY_all_vars_As2_Accuracy':  'Dataset I (loss: As2, score: Accuracy)',\n",
    "                                    'LGBM_SPY_all_vars_As2_AUC':  'Dataset I (loss: As2, score: AUC)',\t\n",
    "                                    'LGBM_SPY_all_vars_As2_Gain_to_pain_ratio_fixed_trans_cost':  'Dataset I (loss: As2, score: Schwager\\'s gain/pain ratio)',\t\n",
    "                                    'LGBM_SPY_all_vars_As2_Calmar_ratio_fixed_trans_cost':  'Dataset I (loss: As2, score: Calmar ratio)',\n",
    "                                    'LGBM_SPY_all_vars_As2_Sharpe_ratio_fixed_trans_cost':  'Dataset I (loss: As2, score: Sharpe ratio)',\n",
    "                                    'LGBM_SPY_all_vars_As2_Sortino_ratio_fixed_trans_cost':  'Dataset I (loss: As2, score: Sortino ratio)',\t\n",
    "                                    'LGBM_SPY_all_vars_As2_CECPP_fixed_trans_cost':  'Dataset I (loss: As2, score: CECPP)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_CE_Accuracy': 'Dataset II (loss: $CE$, score: Accuracy)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_CE_AUC': 'Dataset II (loss: $CE$, score: AUC)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_CE_Gain_to_pain_ratio_fixed_trans_cost': 'Dataset II (loss: $CE$, score: Schwager\\'s gain/pain ratio)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_CE_Calmar_ratio_fixed_trans_cost':  'Dataset II (loss: $CE$, score: Calmar ratio)',\t\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_CE_Sharpe_ratio_fixed_trans_cost':  'Dataset II (loss: $CE$, score: Sharpe ratio)',\t\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_CE_Sortino_ratio_fixed_trans_cost':  'Dataset II (loss: $CE$, score: Sortino ratio)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_CE_CECPP_fixed_trans_cost':  'Dataset II (loss: $CE$, score: CECPP)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_Brier_Accuracy':  'Dataset II (loss: Brier, score: Accuracy)',\t\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_Brier_AUC':  'Dataset II (loss: Brier, score: AUC)',\t\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_Brier_Gain_to_pain_ratio_fixed_trans_cost':  'Dataset II (loss: Brier, score: Schwager\\'s gain/pain ratio)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_Brier_Calmar_ratio_fixed_trans_cost':  'Dataset II (loss: Brier, score: Calmar ratio)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_Brier_Sharpe_ratio_fixed_trans_cost':  'Dataset II (loss: Brier, score: Sharpe ratio)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_Brier_Sortino_ratio_fixed_trans_cost':  'Dataset II (loss: Brier, score: Sortino ratio)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_Brier_CECPP_fixed_trans_cost':  'Dataset II (loss: Brier, score: CECPP)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_Boost_Accuracy':  'Dataset II (loss: Boost, score: Accuracy)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_Boost_AUC':  'Dataset II (loss: Boost, score: AUC)',\t\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_Boost_Gain_to_pain_ratio_fixed_trans_cost':  'Dataset II (loss: Boost, score: Schwager\\'s gain/pain ratio)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_Boost_Calmar_ratio_fixed_trans_cost':  'Dataset II (loss: Boost, score: Calmar ratio)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_Boost_Sharpe_ratio_fixed_trans_cost':  'Dataset II (loss: Boost, score: Sharpe ratio)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_Boost_Sortino_ratio_fixed_trans_cost':  'Dataset II (loss: Boost, score: Sortino ratio)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_Boost_CECPP_fixed_trans_cost':  'Dataset II (loss: Boost, score: CECPP)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_As1_Accuracy':  'Dataset II (loss: As1, score: Accuracy)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_As1_AUC':  'Dataset II (loss: As1, score: AUC)',\t\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_As1_Gain_to_pain_ratio_fixed_trans_cost':  'Dataset II (loss: As1, score: Schwager\\'s gain/pain ratio)',\t\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_As1_Calmar_ratio_fixed_trans_cost':  'Dataset II (loss: As1, score: Calmar ratio)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_As1_Sharpe_ratio_fixed_trans_cost': 'Dataset II (loss: As1, score: Sharpe ratio)',\t\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_As1_Sortino_ratio_fixed_trans_cost': 'Dataset II (loss: As1, score: Sortino ratio)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_As1_CECPP_fixed_trans_cost': 'Dataset II (loss: As1, score: CECPP)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_As2_Accuracy':  'Dataset II (loss: As2, score: Accuracy)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_As2_AUC':  'Dataset II (loss: As2, score: AUC)',\t\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_As2_Gain_to_pain_ratio_fixed_trans_cost':  'Dataset II (loss: As2, score: Schwager\\'s gain/pain ratio)',\t\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_As2_Calmar_ratio_fixed_trans_cost':  'Dataset II (loss: As2, score: Calmar ratio)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_As2_Sharpe_ratio_fixed_trans_cost':  'Dataset II (loss: As2, score: Sharpe ratio)',\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_As2_Sortino_ratio_fixed_trans_cost':  'Dataset II (loss: As2, score: Sortino ratio)',\t\n",
    "                                    'LGBM_SPY_all_vars_plus_patterns_As2_CECPP_fixed_trans_cost':  'Dataset II (loss: As2, score: CECPP)'\n",
    "                                } \n",
    "\n",
    "# Read all RC p-values to a dataframe\n",
    "file_path = folder_path.joinpath('all_p_values.csv')\n",
    "p_values_df = pd.read_csv(file_path, encoding='utf-8', sep = ',', low_memory=False, header = 0, skiprows = 0, skipinitialspace=True)\n",
    "p_values_df = p_values_df.rename(columns = column_mapping)\n",
    "display(p_values_df.shape )\n",
    "\n",
    "## extract all columns that contains 'like' in the labels\n",
    "like = 'Accuracy'\n",
    "p_values_df = p_values_df.filter(like=like, axis=1)\n",
    "display(p_values_df.head() )\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(13, 8) )\n",
    "ax.set_prop_cycle(cycler('color', ['r', 'g', 'b', 'y']) * cycler('marker', ['o', 'v', '^', '>'])) #  cycler('linestyle', ['-', '--', ':', '-.']) \n",
    "p_values_df.plot(kind='line', ax = ax)\n",
    "\n",
    "# set line widths, styles, and markers\n",
    "linewidths = [(i+2)/4. for i in range(p_values_df.shape[1])]\n",
    "for i, line in enumerate(ax.get_lines()):\n",
    "    line.set_linewidth(linewidths[i])\n",
    "#    line.set_linestyle(lines[i])\n",
    "#     line.set_marker(markers[i])\n",
    "\n",
    "# add a horizontal line\n",
    "ax.axhline(y = 0.10, linestyle='--', linewidth = 2, color ='black')\n",
    "ax.text(-6.1, 0.10, \"0.1\")\n",
    "ax.grid(ls=':')\n",
    "ax.legend(fontsize=10, loc='upper center', bbox_to_anchor=(0.5, -0.0), ncol = 2)\n",
    "ax.set_ylabel('RC p-value', fontsize=15)\n",
    "fig.savefig(folder_path.joinpath(f'rc_p_values_{like}.png'), dpi=150, bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "# colors = ['b', 'darkorange', 'y', 'c', 'm', 'k', 'crimson', 'limegreen', 'steelblue', 'gold', 'hotpink', 'maroon']\n",
    "#     markers = ['o', 'v', '^', 'p', '>', '*', 'x', 'h', '+', 'p', \"D\", \"d\"] \n",
    "#     lines = [\"-\", \"--\", \"-.\", (0, (5, 1) ), \"-\", \"--\", (0, (3, 1, 1, 1) ), (0, (5, 1) ), (0, (5, 1)), (0, (3, 1, 1, 1, 1, 1)), (0, (3, 10, 1, 10, 1, 10)), \"-\"]\n",
    "#     linewidths = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
    "#     ax = rmse_df.set_index('date').plot(kind='line', figsize=(10, 8), rot=10, color=colors)\n",
    "\n",
    "#     # set line width and line style\n",
    "#     for i, line in enumerate(ax.get_lines()):\n",
    "#         line.set_linewidth(linewidths[i])\n",
    "#         line.set_linestyle(lines[i])\n",
    "#     #     line.set_marker(markers[i])\n",
    "#     ax.grid(ls=':')\n",
    "#     ax.legend(fontsize=15)\n",
    "#     [l.set_fontsize(13) for l in ax.xaxis.get_ticklabels()]\n",
    "#     [l.set_fontsize(13) for l in ax.yaxis.get_ticklabels()]\n",
    "#     ax.set_ylabel('RMSE', fontsize=15)\n",
    "\n",
    "#     plt.savefig(f'./US_df_big/graphs/rmse_fhorizon_{fhorizon}.pdf', dpi=500)\n",
    "#     print(ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================================================================================== #\n",
    "# Compare the Performance of a Trading Strategy based on Technical Indicators vs. Price Patterns across Multiple Forecasting Horizons for a given Loss Function and Scoring Function \n",
    "# =========================================================================================================================================== #\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from varname import nameof\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "#Gradient Color Bar Plots\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from matplotlib import colors as mcolors, path\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import joblib\n",
    "import multiprocessing\n",
    "# import dask\n",
    "# import distributed\n",
    "# dask.config.set({\"distributed.comm.timeouts.tcp\": \"100000s\", \"distributed.scheduler.allowed-failures\": 999})\n",
    "# num_cores = multiprocessing.cpu_count()\n",
    "num_cores = 30\n",
    "\n",
    "##### Set the current working directory\n",
    "path=\"e:/Copy/SCRIPTS/Forecast_Stocks/Jupyter_notebooks/\"\n",
    "os.chdir(path)\n",
    "\n",
    "##### Joint-boxplot a performance statistic of a trading strategy over forecasting horizons with hue = 'algos'\n",
    "def joint_plot( algos = ['RF_SPY_all_vars', 'RF_SPY_all_vars_plus_patterns'],\n",
    "                        loss_fn = 'CE',\n",
    "                        score_fn_dict = {'Schwager\\'s gain/pain ratio': 'Gain_to_pain_ratio_fixed_trans_cost'},\n",
    "                        taus = [1, 2, 4, 6, 8, 10, 12],\n",
    "                        init_wealth = 1000,\n",
    "                        invest_window = 200,\n",
    "                        trans_cost = 0.5,\n",
    "                        perf_stats_dict = {  'Average Number of Trades': 'average_number_of_trades',\n",
    "                                                        'Percentage of Winning Trades': 'percentage_of_winning_trades',\t\n",
    "                                                        'Largest Simple Return':   'largest_raw_return',\t\n",
    "                                                        'Smallest Simple Return':    'smallest_raw_return',\t\n",
    "                                                        'Ratio of Average Winning Trade to Average Losing Trade': 'ratio_win_loss',\t\n",
    "                                                        'Maximum Number of Consecutive Winners': 'max_number_of_consecutive_winners',\t\n",
    "                                                        'Maximum Number of Consecutive Losers':    'max_number_of_consecutive_losers', \n",
    "                                                        'Risk-Adjusted Annualized Excess Return':    'annualized_excess_return',\t\n",
    "                                                        'Annualized Standard Deviation':    'annualized_standard_deviation',\t\n",
    "                                                        'Maximum Drawdown':   'max_drawdown',\t\n",
    "                                                        'Schwager\\'s Gain to Pain Ratio': 'Schwager_gain-to-pain_ratio',\t\n",
    "                                                        'Calmar Ratio':  'Calmar_ratio',\t\n",
    "                                                        'Sharpe Ratio':    'Sharpe_ratio',\t\n",
    "                                                        'Sortino Ratio': 'Sortino_ratio',\n",
    "                                                        'CECPP': 'cecpp',\n",
    "                                                        'Morningstar\\'s risk-adjusted rating': 'mrar'}\n",
    "                        ):\n",
    "\n",
    "    ''' Joint plot performance statistics of a trading strategy over over different values of the forecasting horizon\n",
    "    INPUT\n",
    "        algos: ML algorithms used to forecast price movement directions\n",
    "        loss_fn: a loss function used to train a ML model\n",
    "        score_fn_dict: a scoring function used to cross-validate a ML model\n",
    "            (i.e., score_fn_dict is in the dictionary: {  'Accuracy': 'Accuracy', 'AUC': 'AUC',  'Schwager\\'s gain/pain ratio': 'Gain_to_pain_ratio_fixed_trans_cost', \\\n",
    "                                                                                'Calmar ratio': 'Calmar_ratio_fixed_trans_cost', 'Sharpe ratio': 'Sharpe_ratio_fixed_trans_cost', \\\n",
    "                                                                                'Sortino ratio': 'Sortino_ratio_fixed_trans_cost',  'CECPP': 'CECPP_fixed_trans_cost'} for the fixed cost strategy}\n",
    "            )\n",
    "        taus: a list of forecasting horizons\n",
    "        init_wealth: an initial wealth\n",
    "        invest_window: a trading window\n",
    "        trans_cost: a  value of transaction cost (i.e., {0.05, 0.1, 0.5, 1.0} for the fixed cost strategy and {0.0005, 0.001, 0.005, 0.01} for the variable cost strategy)\n",
    "        perf_stats_dict: a dictionary of performance statistics\n",
    "    OUTPUT\n",
    "        joint boxplots of a performance statistic across multiple forecasting horizons\n",
    "    '''\n",
    "    \n",
    "    # retrieve the name of the scoring function\n",
    "    score_fn_dict_key = list(score_fn_dict.keys())[0]\n",
    "    score_fn_dict_value = list(score_fn_dict.values())[0]\n",
    "    # print(score_fn_dict_value)\n",
    "    \n",
    "    algo_word = re.search(r'\\w+(?=\\_all)',  algos[0], flags=re.IGNORECASE | re.VERBOSE).group()\n",
    "    out_dir = f'../Results/graphs/{algo_word}/'\n",
    "    if not os.path.exists( out_dir ):\n",
    "    # create the directory if it does not exist .\n",
    "        os.makedirs( out_dir )\n",
    "        \n",
    "    use_strategy = 'fixed_trans_cost'\n",
    "    try:\n",
    "        use_strategy = re.search(fr'(?<={score_fn_dict_key.split()[-1]}_)\\w+', score_fn_dict_value, flags=re.IGNORECASE | re.VERBOSE).group().lower() \n",
    "    except:\n",
    "        pass\n",
    "    # print(use_strategy)\n",
    "    \n",
    "    # import data into dataframes\n",
    "    try:\n",
    "        list_dfs = [[] for _ in np.arange( len(algos) )]\n",
    "        for i in np.arange(len(algos)):\n",
    "            for tau in taus:\n",
    "                performance_df = pd.read_csv(f'../Results/{algos[i]}/loss_fn={loss_fn}/score_fn={score_fn_dict_value}/tau={tau}/performance/' +\n",
    "                                                                    f'performance_hper_{invest_window}_init_wealth_{init_wealth}_{use_strategy}_{trans_cost}.csv', \\\n",
    "                                                                        engine = 'python', encoding='utf-8', skipinitialspace=True, sep = ',', parse_dates=['start_date', 'end_date'], index_col = 'end_date')\n",
    "                performance_df['annualized_excess_return'] = performance_df['annualized_excess_return'].values / performance_df['annualized_standard_deviation'].values\n",
    "                performance_df.drop(columns = ['start_date', 'ratio_profit_over_total_loss',  'annualized_return', 'annualized_return_bh'], axis = 1, inplace = True)\n",
    "                # # scale down the values of the Calmar ratio so that all the variables are roughly on the same scale\n",
    "                # performance_df['Calmar_ratio'] = StandardScaler(with_mean=False).fit_transform( performance_df['Calmar_ratio'].values.reshape(-1,1) )\n",
    "                # display(performance_df.head() )\n",
    "                list_dfs[i].append(performance_df)\n",
    "    except Exception as er:\n",
    "        print(er)\n",
    "        \n",
    "    # display(list_dfs[0].head())\n",
    "\n",
    "    # melt all the dataframes to a long dataframe\n",
    "    list_metric_dfs = []\n",
    "    perf_stats_values = list( perf_stats_dict.values() )\n",
    "    \n",
    "    for i in np.arange( len(algos) ):\n",
    "        for j in np.arange( len(taus) ):\n",
    "            metric_df = list_dfs[i][j][perf_stats_values].reset_index(drop = False)\n",
    "            metric_melted_df = pd.melt(metric_df, id_vars = 'end_date', var_name='perf_stats', value_name='value')\n",
    "            metric_melted_df['tau'] = [taus[j] for _ in range( len(metric_melted_df ) )]\n",
    "            metric_melted_df['predictor_set'] = [algos[i] for _ in range( len(metric_melted_df ) )]\n",
    "            list_metric_dfs.append(metric_melted_df)\n",
    "    merged_df = pd.concat(list_metric_dfs, axis = 0)\n",
    "    # display( merged_df.head() )\n",
    "    # merged_df.to_csv(os.path.join(out_dir, 'merged_data.csv'), index=False, header = True) \n",
    "\n",
    "    # joint boxplot each performance statistic\n",
    "    perf_stats_keys = list( perf_stats_dict.keys() )\n",
    "    for i in np.arange( len(perf_stats_dict) ):\n",
    "        print('Performance metric: %s' % perf_stats_values[i])\n",
    "        fig, ax = plt.subplots( figsize=(13, 8) )\n",
    "        perf_stat_df = merged_df[ merged_df['perf_stats'] == perf_stats_values[i] ].reset_index(drop = True)\n",
    "        # display( perf_stat_df.head() )\n",
    "        ax = sns.boxplot(x = 'tau', y = 'value', hue = 'predictor_set', data=perf_stat_df)\n",
    "        sns.stripplot(x = 'tau', y = 'value',   hue = 'predictor_set', data=perf_stat_df, jitter=0.12, dodge=True, palette='dark:gray', size=2, alpha=0.8, ax = ax)\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.axhline(0, ls = '--', linewidth = 2, color ='red') \n",
    "        # ax.axhline(1, ls = '--', linewidth = 1, color ='red') \n",
    "        # ax.text(0, 1, \"1\", ha=\"center\", va=\"center\")\n",
    "        ax.grid(ls=':')\n",
    "        ax.legend(handles = handles, labels = ['Dataset I', 'Dataset II'], loc = 'upper right', title = 'Set of Predictors')\n",
    "        ax.set_ylabel(perf_stats_keys[i], fontsize=15)\n",
    "        ax.set_xlabel('Forecasting Horizon', fontsize=15)\n",
    "        ax.tick_params(axis='x', which='major', labelsize=13, labelrotation=0)        \n",
    "        out_file = f'{out_dir}/joint_boxplot_all_fhorizons_{loss_fn}_{score_fn_dict_value}_{invest_window}_{perf_stats_values[i]}_{use_strategy}_{trans_cost}.png'\n",
    "        fig.savefig(out_file, dpi=150, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "    del perf_stat_df, merged_df, metric_df, performance_df\n",
    "    gc.collect()\n",
    "\n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    startTime = time.time()\n",
    "\n",
    "    # Define a list of algorithms employed\n",
    "    # algos = ['RF_SPY_all_vars', 'RF_SPY_all_vars_plus_patterns']\n",
    "    algos = ['LGBM_SPY_all_vars', 'LGBM_SPY_all_vars_plus_patterns']\n",
    "\n",
    "    # Define a list of loss functions used to train a ML model\n",
    "    loss_fns = ['CE', 'Brier', 'Boost', 'As1', 'As2']\n",
    "    # loss_fns = ['CE']\n",
    "\n",
    "    # Define a list of score functions used to cross validate a ML algorithm\n",
    "    # score_fns_dict = [{'Accuracy': 'Accuracy'}, \\\n",
    "    #                              {'AUC': 'AUC'},  \\\n",
    "    #                              {'Schwager\\'s gain/pain ratio': 'Gain_to_pain_ratio_fixed_trans_cost'}, \\\n",
    "    #                              {'Calmar ratio': 'Calmar_ratio_fixed_trans_cost'}, \n",
    "    #                              {'Sharpe ratio': 'Sharpe_ratio_fixed_trans_cost'}, \\\n",
    "    #                              {'Sortino ratio': 'Sortino_ratio_fixed_trans_cost'},  \n",
    "    #                              {'CECPP': 'CECPP_fixed_trans_cost'}]\n",
    "    score_fns_dict = [{'Accuracy': 'Accuracy'}, \\\n",
    "                                 {'AUC': 'AUC'},  \\\n",
    "                                 {'Schwager\\'s gain/pain ratio': 'Gain_to_pain_ratio_fixed_trans_cost'}, \\\n",
    "                                 {'Sharpe ratio': 'Sharpe_ratio_fixed_trans_cost'}, \\\n",
    "                                 {'CECPP': 'CECPP_fixed_trans_cost'}]\n",
    "\n",
    "    # Define a list of holding periods\n",
    "    invest_windows = [100, 200]\n",
    "    \n",
    "    # Define a list of transaction costs\n",
    "    trans_costs = [0.05, 0.1, 0.5, 1.0]\n",
    "    \n",
    "    for loss_fn in loss_fns:\n",
    "        for score_fn_dict in score_fns_dict:\n",
    "            for invest_window in invest_windows:\n",
    "                for trans_cost in trans_costs:\n",
    "                    joint_plot(algos = algos, \n",
    "                                    loss_fn = loss_fn, \n",
    "                                    score_fn_dict = score_fn_dict,\n",
    "                                    taus = [1, 2, 4, 6, 8, 10, 12],\n",
    "                                    invest_window = invest_window,\n",
    "                                    trans_cost = trans_cost\n",
    "                                    )\n",
    "    \n",
    "    # joint_plot()\n",
    "\n",
    "    \n",
    "    print( 'The script took {} second !'.format(time.time() - startTime) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc917ebd80857c8984278d262088eb38f6d12477c79ef5a6d94d7dc2b555f094"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
